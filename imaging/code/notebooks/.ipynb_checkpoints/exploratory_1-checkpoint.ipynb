{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ce340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"scripts\")  # Add the path to the scripts folder\n",
    "#import script_file_1\n",
    "\n",
    "import h5py\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "573171c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of file_paths to loop over and extract data from \n",
    "sess_dir = 'C:/code/SMTB_2023/imaging/data/5546'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd90dca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['dims', 'dview', 'estimates', 'params', 'remove_very_bad_comps', 'skip_refinement']>\n",
      "<KeysViewHDF5 ['A', 'A_thr', 'Ab', 'Ab_dense', 'AtA', 'AtY_buf', 'C', 'CC', 'CY', 'C_on', 'Cf', 'F_dff', 'OASISinstances', 'R', 'S', 'SNR_comp', 'W', 'YrA', 'Yr_buf', 'b', 'b0', 'bl', 'c1', 'center', 'cnn_preds', 'dims', 'discarded_components', 'ecc', 'f', 'g', 'idx_components', 'idx_components_bad', 'ind_new', 'lam', 'mn', 'neurons_sn', 'noisyC', 'nr', 'r_values', 'rho_buf', 'shifts', 'sn', 'sv', 'vr']>\n"
     ]
    }
   ],
   "source": [
    "file_path = 'C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_.hdf5'\n",
    "with h5py.File(file_path, 'r') as hdf_file:\n",
    "    print(hdf_file.keys())\n",
    "    print(hdf_file['estimates'].keys())\n",
    "    data = hdf_file['estimates']['C'][:]\n",
    "\n",
    "file_path_write = file_path.replace('.hdf5', '.pkl')\n",
    "with open(file_path_write, 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TIMESTAMP_CONCAT_ALIGN.IPYNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f8c6806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load both pkls and combine them into one \n",
    "behavior_output_path = sess_dir + '/forCaiman.pkl'\n",
    "with open(behavior_output_path, 'rb') as file:\n",
    "    cv, boris1 = pickle.load(file)\n",
    "with open(file_path_write, 'rb') as file:\n",
    "    C_array = pickle.load(file)\n",
    "\n",
    "    \n",
    "file_path_total = file_path_write.replace('.pkl', 'total.pkl')\n",
    "with open(file_path_total, 'wb') as f:\n",
    "    pickle.dump([C_array, cv, boris1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e0c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD DATA\n",
    "\n",
    "\n",
    "files_to_analyze = ['C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_total.pkl']\n",
    "with open(files_to_analyze[0], 'rb') as file:\n",
    "    C_array, cv, boris1 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adee6c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 53613)\n"
     ]
    }
   ],
   "source": [
    "print(C_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b59b541e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(384, 7)\n"
     ]
    }
   ],
   "source": [
    "print(cv.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06ce94a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    }
   ],
   "source": [
    "print(type(boris1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9b21e50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Observation id</th>\n",
       "      <th>Observation date</th>\n",
       "      <th>Description</th>\n",
       "      <th>Media file</th>\n",
       "      <th>Total length</th>\n",
       "      <th>FPS</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Behavior</th>\n",
       "      <th>Behavioral category</th>\n",
       "      <th>Modifiers</th>\n",
       "      <th>Behavior type</th>\n",
       "      <th>Start (s)</th>\n",
       "      <th>Stop (s)</th>\n",
       "      <th>Duration (s)</th>\n",
       "      <th>Comment start</th>\n",
       "      <th>Comment stop</th>\n",
       "      <th>startFrameNum</th>\n",
       "      <th>endFrameNum</th>\n",
       "      <th>scopeFrameStart</th>\n",
       "      <th>scopeFrameEnd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Both</td>\n",
       "      <td>STATE</td>\n",
       "      <td>8.80</td>\n",
       "      <td>10.30</td>\n",
       "      <td>1.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>440</td>\n",
       "      <td>515</td>\n",
       "      <td>140</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>10.54</td>\n",
       "      <td>13.88</td>\n",
       "      <td>3.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>527</td>\n",
       "      <td>694</td>\n",
       "      <td>168</td>\n",
       "      <td>220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>25.18</td>\n",
       "      <td>32.80</td>\n",
       "      <td>7.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1259</td>\n",
       "      <td>1640</td>\n",
       "      <td>400</td>\n",
       "      <td>520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>33.88</td>\n",
       "      <td>36.14</td>\n",
       "      <td>2.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1694</td>\n",
       "      <td>1807</td>\n",
       "      <td>538</td>\n",
       "      <td>574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>grooming</td>\n",
       "      <td>Affiliative</td>\n",
       "      <td>Grooming self</td>\n",
       "      <td>STATE</td>\n",
       "      <td>48.28</td>\n",
       "      <td>59.40</td>\n",
       "      <td>11.12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2414</td>\n",
       "      <td>2970</td>\n",
       "      <td>766</td>\n",
       "      <td>942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>3328.98</td>\n",
       "      <td>3331.02</td>\n",
       "      <td>2.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166449</td>\n",
       "      <td>166551</td>\n",
       "      <td>52813</td>\n",
       "      <td>52846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>grooming</td>\n",
       "      <td>Affiliative</td>\n",
       "      <td>Grooming self</td>\n",
       "      <td>STATE</td>\n",
       "      <td>3338.70</td>\n",
       "      <td>3343.04</td>\n",
       "      <td>4.34</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>166935</td>\n",
       "      <td>167152</td>\n",
       "      <td>52967</td>\n",
       "      <td>53036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>3349.78</td>\n",
       "      <td>3361.64</td>\n",
       "      <td>11.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>167489</td>\n",
       "      <td>168082</td>\n",
       "      <td>53143</td>\n",
       "      <td>53331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>grooming</td>\n",
       "      <td>Affiliative</td>\n",
       "      <td>Grooming self</td>\n",
       "      <td>STATE</td>\n",
       "      <td>3370.38</td>\n",
       "      <td>3372.16</td>\n",
       "      <td>1.78</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168519</td>\n",
       "      <td>168608</td>\n",
       "      <td>53470</td>\n",
       "      <td>53498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>5546_1215_135620</td>\n",
       "      <td>2022-12-26 20:58:00</td>\n",
       "      <td>First hour of cohousing</td>\n",
       "      <td>C:/miniscopeData/5546/2022_12_15/13_56_20_reco...</td>\n",
       "      <td>3379.44</td>\n",
       "      <td>50.0</td>\n",
       "      <td>No focal subject</td>\n",
       "      <td>noncontact investigation</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>Initiating</td>\n",
       "      <td>STATE</td>\n",
       "      <td>3376.74</td>\n",
       "      <td>3378.72</td>\n",
       "      <td>1.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>168837</td>\n",
       "      <td>168936</td>\n",
       "      <td>53570</td>\n",
       "      <td>53602</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>308 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Observation id     Observation date              Description  \\\n",
       "0    5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "1    5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "2    5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "3    5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "4    5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "..                ...                  ...                      ...   \n",
       "303  5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "304  5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "305  5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "306  5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "307  5546_1215_135620  2022-12-26 20:58:00  First hour of cohousing   \n",
       "\n",
       "                                            Media file  Total length   FPS  \\\n",
       "0    C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "1    C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "2    C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "3    C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "4    C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "..                                                 ...           ...   ...   \n",
       "303  C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "304  C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "305  C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "306  C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "307  C:/miniscopeData/5546/2022_12_15/13_56_20_reco...       3379.44  50.0   \n",
       "\n",
       "              Subject                  Behavior Behavioral category  \\\n",
       "0    No focal subject  noncontact investigation       Investigation   \n",
       "1    No focal subject  noncontact investigation       Investigation   \n",
       "2    No focal subject  noncontact investigation       Investigation   \n",
       "3    No focal subject  noncontact investigation       Investigation   \n",
       "4    No focal subject                  grooming         Affiliative   \n",
       "..                ...                       ...                 ...   \n",
       "303  No focal subject  noncontact investigation       Investigation   \n",
       "304  No focal subject                  grooming         Affiliative   \n",
       "305  No focal subject  noncontact investigation       Investigation   \n",
       "306  No focal subject                  grooming         Affiliative   \n",
       "307  No focal subject  noncontact investigation       Investigation   \n",
       "\n",
       "         Modifiers Behavior type  Start (s)  Stop (s)  Duration (s)  \\\n",
       "0             Both         STATE       8.80     10.30          1.50   \n",
       "1       Initiating         STATE      10.54     13.88          3.34   \n",
       "2       Initiating         STATE      25.18     32.80          7.62   \n",
       "3       Initiating         STATE      33.88     36.14          2.26   \n",
       "4    Grooming self         STATE      48.28     59.40         11.12   \n",
       "..             ...           ...        ...       ...           ...   \n",
       "303     Initiating         STATE    3328.98   3331.02          2.04   \n",
       "304  Grooming self         STATE    3338.70   3343.04          4.34   \n",
       "305     Initiating         STATE    3349.78   3361.64         11.86   \n",
       "306  Grooming self         STATE    3370.38   3372.16          1.78   \n",
       "307     Initiating         STATE    3376.74   3378.72          1.98   \n",
       "\n",
       "     Comment start  Comment stop  startFrameNum  endFrameNum  scopeFrameStart  \\\n",
       "0              NaN           NaN            440          515              140   \n",
       "1              NaN           NaN            527          694              168   \n",
       "2              NaN           NaN           1259         1640              400   \n",
       "3              NaN           NaN           1694         1807              538   \n",
       "4              NaN           NaN           2414         2970              766   \n",
       "..             ...           ...            ...          ...              ...   \n",
       "303            NaN           NaN         166449       166551            52813   \n",
       "304            NaN           NaN         166935       167152            52967   \n",
       "305            NaN           NaN         167489       168082            53143   \n",
       "306            NaN           NaN         168519       168608            53470   \n",
       "307            NaN           NaN         168837       168936            53570   \n",
       "\n",
       "     scopeFrameEnd  \n",
       "0              164  \n",
       "1              220  \n",
       "2              520  \n",
       "3              574  \n",
       "4              942  \n",
       "..             ...  \n",
       "303          52846  \n",
       "304          53036  \n",
       "305          53331  \n",
       "306          53498  \n",
       "307          53602  \n",
       "\n",
       "[308 rows x 20 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boris1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "53c3a27a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['noncontact investigation', 'grooming', 'lunge or bite',\n",
       "       'contact investigation', 'mount', 'intromission', 'ejaculation',\n",
       "       'boxing', 'food (eating', 'tumble fighting'], dtype=object)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boris1['Behavior'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "456c3da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53602\n"
     ]
    }
   ],
   "source": [
    "print(boris1.scopeFrameEnd.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae5cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08489556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.9995896517635647"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "107204 / 53613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "70bebe12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def visualize_2D_matrix_with_shading(matrix, behavior_df, behavior_name, default_vmax=1.0):\n",
    "    def update_plot(colormap, vmin, vmax):\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(matrix, cmap=colormap, vmin=vmin, vmax=vmax, aspect='auto')\n",
    "        plt.colorbar()\n",
    "        plt.title(\"One-Photon Calcium Imaging 2D Matrix\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neurons\")\n",
    "        \n",
    "        # Get 'scopeFrameStart' and 'scopeFrameEnd' values for the specified behavior name\n",
    "        behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "        start_frames = behavior_data['scopeFrameStart'].values\n",
    "        end_frames = behavior_data['scopeFrameEnd'].values\n",
    "        \n",
    "        # Plot shaded regions for 'scopeFrameStart' and 'scopeFrameEnd'\n",
    "        for start_frame, end_frame in zip(start_frames, end_frames):\n",
    "            plt.axvspan(start_frame, end_frame, color='lightblue', alpha=0.6)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    # Define interactive widgets (same as before)\n",
    "    colormap_selector = widgets.Dropdown(\n",
    "        options=['viridis', 'plasma', 'inferno', 'magma', 'cividis'],\n",
    "        value='viridis',\n",
    "        description='Colormap:',\n",
    "    )\n",
    "\n",
    "    vmin_slider = widgets.FloatSlider(\n",
    "        value=np.min(matrix),\n",
    "        min=np.min(matrix),\n",
    "        max=np.max(matrix),\n",
    "        step=0.1,\n",
    "        description='Min Value:',\n",
    "    )\n",
    "    \n",
    "    vmax_slider = widgets.FloatSlider(\n",
    "        value=default_vmax,\n",
    "        min=np.min(matrix),\n",
    "        max=np.max(matrix),\n",
    "        step=0.1,\n",
    "        description='Max Value:',\n",
    "    )\n",
    "\n",
    "    # Create the interactive plot (same as before)\n",
    "    interactive_plot = widgets.interactive(\n",
    "        update_plot,\n",
    "        colormap=colormap_selector,\n",
    "        vmin=vmin_slider,\n",
    "        vmax=vmax_slider,  # Using the checkbox value directly for vmax_auto\n",
    "    )\n",
    "\n",
    "    display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76150a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c0ea233",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ff231282704bf4b93b09caf05d8ece",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='Colormap:', options=('viridis', 'plasma', 'inferno', 'magma', 'civ…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "default_vmax = 1.0\n",
    "visualize_2D_matrix_with_shading(C_array, boris1, 'mount', default_vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4547fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transient_timestamps(\n",
    "    neural_data, thresh_type=\"eps\", do_zscore=True, std_thresh=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts an array of continuous time series (e.g., traces or S)\n",
    "    into lists of timestamps where activity exceeds some threshold.\n",
    "\n",
    "    :parameters\n",
    "    ---\n",
    "    neural_data: (neuron, time) array\n",
    "        Neural time series, (e.g., C or S).\n",
    "\n",
    "    std_thresh: float\n",
    "        Number of standard deviations above the mean to define threshold.\n",
    "\n",
    "    :returns\n",
    "    ---\n",
    "    event_times: list of length neuron\n",
    "        Each entry in the list contains the timestamps of a neuron's\n",
    "        activity.\n",
    "\n",
    "    event_mags: list of length neuron\n",
    "        Event magnitudes.\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute thresholds for each neuron.\n",
    "    neural_data = np.asarray(neural_data, dtype=np.float32)\n",
    "    if thresh_type == \"eps\":\n",
    "        thresh = np.repeat(np.finfo(np.float32).eps, neural_data.shape[0])\n",
    "    else:\n",
    "        if do_zscore:\n",
    "            stds = np.std(neural_data, axis=1)\n",
    "            #print(stds.shape)\n",
    "            means = np.mean(neural_data, axis=1)\n",
    "            thresh = means + std_thresh * stds\n",
    "        else:\n",
    "            thresh = np.repeat(std_thresh, neural_data.shape[0])\n",
    "\n",
    "    # Get event times and magnitudes.\n",
    "    bool_arr = neural_data > np.tile(thresh, [neural_data.shape[1], 1]).T\n",
    "\n",
    "    event_times = [np.where(neuron > t)[0] for neuron, t in zip(neural_data, thresh)]\n",
    "\n",
    "    event_mags = [neuron[neuron > t] for neuron, t in zip(neural_data, thresh)]\n",
    "\n",
    "    return event_times, event_mags, bool_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2143a2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57,)\n"
     ]
    }
   ],
   "source": [
    "events, magnitudes, bool_arr = get_transient_timestamps(C_array, thresh_type='zscore', std_thresh=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fd24abe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(57, 53613)\n"
     ]
    }
   ],
   "source": [
    "print(std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0c831c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True, False, ..., False, False, False],\n",
       "       [ True,  True,  True, ...,  True,  True,  True],\n",
       "       [False, False, False, ..., False,  True,  True],\n",
       "       ...,\n",
       "       [ True,  True,  True, ..., False,  True, False],\n",
       "       [ True,  True,  True, ...,  True,  True, False],\n",
       "       [False, False, False, ..., False, False,  True]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a728b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_2D_matrix_with_shading(bool_arr, boris1, '', default_vmax=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2649449b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_single_row(matrix, row_index):\n",
    "    def update_plot(view_start, view_end):\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.plot(matrix[row_index], color='b', lw=2)\n",
    "        plt.xlim(view_start, view_end)\n",
    "        plt.title(f\"Raw Signal - Neuron {row_index}\")\n",
    "        plt.xlabel(\"Time (frames)\")\n",
    "        plt.ylabel(\"Signal Intensity (DF/F)\")\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # Get the number of time points in the row\n",
    "    num_time_points = matrix.shape[1]\n",
    "    \n",
    "    # Define interactive widgets\n",
    "    view_start_slider = widgets.FloatSlider(\n",
    "        value=0,\n",
    "        min=0,\n",
    "        max=num_time_points - 1,\n",
    "        step=1,\n",
    "        description='View Start:',\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    view_end_slider = widgets.FloatSlider(\n",
    "        value=num_time_points - 1,\n",
    "        min=0,\n",
    "        max=num_time_points - 1,\n",
    "        step=1,\n",
    "        description='View End:',\n",
    "        continuous_update=False,\n",
    "    )\n",
    "\n",
    "    # Create the interactive plot\n",
    "    interactive_plot = widgets.interactive(\n",
    "        update_plot,\n",
    "        view_start=view_start_slider,\n",
    "        view_end=view_end_slider,\n",
    "    )\n",
    "\n",
    "    display(interactive_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_plot = 3\n",
    "plot_single_row(C_array, row_to_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4c1a69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_time_locked_responses(matrix, behavior_df, behavior_name, window_before_sec=1, window_after_sec=1, frame_rate=15):\n",
    "    # Convert time windows from seconds to frames\n",
    "    window_before_frames = int(window_before_sec * frame_rate)\n",
    "    window_after_frames = int(window_after_sec * frame_rate)\n",
    "\n",
    "    # Get the behavior data for the specified behavior name\n",
    "    behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "    behavior_start_frame = behavior_data['scopeFrameStart'].values[0]\n",
    "    behavior_end_frame = behavior_data['scopeFrameEnd'].values[0]\n",
    "\n",
    "    # Calculate the view start and view end based on the specified window_before_frames and window_after_frames\n",
    "    view_start = behavior_start_frame - window_before_frames\n",
    "    view_end = behavior_end_frame + window_after_frames\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.close()  # Close the previous figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Calculate the time points relative to the behavior event in seconds\n",
    "    time_points = np.linspace(-window_before_sec, window_after_sec, view_end - view_start + 1)\n",
    "\n",
    "    # Extract the time-locked responses for all cells\n",
    "    time_locked_responses = matrix[:, view_start:view_end + 1]\n",
    "\n",
    "    # Calculate mean and standard deviation across all cells for each time point\n",
    "    mean_response = np.mean(time_locked_responses, axis=0)\n",
    "    std_response = np.std(time_locked_responses, axis=0)\n",
    "\n",
    "    # Plot mean and standard deviation\n",
    "    plt.plot(time_points, mean_response, color='b', lw=2, label='Mean')\n",
    "    plt.fill_between(time_points, mean_response - std_response, mean_response + std_response,\n",
    "                     color='b', alpha=0.3, label='Standard Deviation')\n",
    "\n",
    "    plt.axvline(0, color='gray', linestyle='--', alpha=0.5)  # Vertical line at behavior event\n",
    "\n",
    "    plt.title(f\"Time-Locked Responses to Behavior: {behavior_name}\")\n",
    "    plt.xlabel(\"Time Relative to Behavior Event (seconds)\")\n",
    "    plt.ylabel(\"Mean Calcium Signal\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cb75d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 15\n",
    "window_before_sec = 2\n",
    "window_after_sec = 2\n",
    "plot_time_locked_responses(C_array, boris1, 'mount',window_before_sec, window_after_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541616e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616cf15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1aee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pdb #for debugging\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import auc\n",
    "import pickle\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# ideally loop through multiple directories, load variables into single object per animal,\n",
    "# and then have core functions to loop the objects through, with a plotter that\n",
    "# pulls the outputs together \n",
    "\n",
    "\n",
    "day0 = \"C://miniscopeData/5546/2022_12_15/13_56_20_record/12152022_cohabitation_5546\"\n",
    "day1 = \"C://miniscopeData/5546/2022_12_16/14_36_12/121622_cohousing_5546\"\n",
    "day2 = \"C://miniscopeData/5546/2022_12_17/12_48_22\"\n",
    "partner=\"Left\"\n",
    "novel=\"Right\"\n",
    "runPartner1OrNovel0 = 0\n",
    "\n",
    "day14 = \"C://miniscopeData/5546/2023_01_01/13_17_27/01012023_PPTnodrug\"\n",
    "partnerDay14=\"Right\"\n",
    "novelDay14=\"Left\"\n",
    "\n",
    "\n",
    "mainDir = day0\n",
    "mainDirName = 'day0'\n",
    "\n",
    "loadDir = os.path.join(mainDir + '/alignerOutput')\n",
    "\n",
    "\n",
    "generalOutDir = \"C://miniscopeData/5546\"\n",
    "writeOutDir = os.path.join(generalOutDir + '/analysesOutput')\n",
    "isExist = os.path.exists(writeOutDir)\n",
    "if not isExist:\n",
    "    os.makedirs(writeOutDir)\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(loadDir + '/minianOut.pkl'), 'rb') as f:\n",
    "    cellsKept, cellsKeptSpikes, cv,boris1 = pickle.load(f)\n",
    "    \n",
    "#cellsKept, cellsKeptSpikes, cv, boris1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch cell, to look at downsampling of Minian, to make sure indices are appropriate\n",
    "#temporal downsampling by 2 on Minian, so this should also be 2\n",
    "#also transposes for corr matrix and PCA cells\n",
    "\n",
    "columnNames = cellsKept.columns\n",
    "numMinianFrames = max(columnNames)\n",
    "numMinianDownsample = cellsKept.shape[1]\n",
    "\n",
    "downsampleFactor = numMinianFrames / numMinianDownsample\n",
    "print(downsampleFactor)\n",
    "\n",
    "dsFactorUsed = 2\n",
    "\n",
    "#print(numMinianFrames)\n",
    "\n",
    "cellsKept.shape[0]\n",
    "cellsTransposed = cellsKept.transpose()\n",
    "\n",
    "\n",
    "#print(cellsKept.shape[1])\n",
    "#cellsKept.iloc[(cellsKept['frame']-32).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ca63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellsKept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORR MATRIX ACROSS SESSION\n",
    "\n",
    "import seaborn as sns \n",
    "#print(cellsTransposed)\n",
    "matrix = cellsTransposed.corr()\n",
    "mask_ut = np.triu(np.ones(matrix.shape)).astype(bool)\n",
    "fig = plt.figure()\n",
    "hmap = sns.heatmap(matrix,mask=mask_ut,vmin=-1,vmax=1,cmap=\"Spectral\")\n",
    "\n",
    "fileName = mainDirName + 'overallCorrMatrix.png'\n",
    "saveFolder = os.path.join(writeOutDir,'corrMatrix/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "fig.savefig(saveName)\n",
    "\n",
    "#print(matrix)\n",
    "#plt.matshow(matrix)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a63cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(X):\n",
    "    # X: ndarray, shape (n_features, n_samples)\n",
    "    ss = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xz = ss.fit_transform(X.T).T\n",
    "    return Xz\n",
    "\n",
    "cellsKept = z_score(cellsKept)\n",
    "\n",
    "print(cellsKept.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA ACROSS SESSION\n",
    "\n",
    "#pip install pca\n",
    "\n",
    "from pca import pca\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "    \n",
    "def center(X):\n",
    "    # X: ndarray, shape (n_features, n_samples)\n",
    "    ss = StandardScaler(with_mean=True, with_std=False)\n",
    "    Xc = ss.fit_transform(X.T).T\n",
    "    return Xc\n",
    "\n",
    "\n",
    "#cellsKeptCentered = center(cellsTransposed)\n",
    "#cellsKeptCenteredTransposed = cellsKeptCentered.transpose()\n",
    "\n",
    "\n",
    "\n",
    "model = pca(n_components=0.99, normalize=True)\n",
    "results = model.fit_transform(cellsTransposed)\n",
    "fig,ax = model.plot()\n",
    "\n",
    "# Make scatterplot\n",
    "#model.scatter()\n",
    "\n",
    "# Gradient over the samples. High dense areas will be more colourful.\n",
    "#model.scatter(gradient='#FFFFFF')\n",
    "\n",
    "# Include the outlier detection\n",
    "#model.scatter(SPE=True)\n",
    "\n",
    "# Include the outlier detection\n",
    "#model.scatter(hotellingt2=True)\n",
    "\n",
    "# Look at different PCs: 1st PC=1  vs PC=3\n",
    "#model.scatter(PC=[0, 2])\n",
    "\n",
    "#fileName = mainDirName + 'overallPCA.png'\n",
    "#saveFolder = os.path.join(writeOutDir,'PCA/')\n",
    "\n",
    "#isExist = os.path.exists(saveFolder)\n",
    "#if not isExist:\n",
    "#    os.makedirs(saveFolder)\n",
    "    \n",
    "#saveName = saveFolder + fileName\n",
    "#fig.savefig(saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(matrixIn,directory):\n",
    "    model = pca(n_components=0.95)\n",
    "    results = model.fit_transform(matrixIn)\n",
    "    fig,ax = model.plot()\n",
    "    fig.savefig(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boris1.Behavior\n",
    "behaviorUniques = list(set([car for car in boris1.Behavior]))\n",
    "behaviorUniques\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## optional cell for warping behavior and neural data to accomodate equal event totals\n",
    "\n",
    "# modify boris1. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea0fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pulling out events and corresponding data \n",
    "\n",
    "behaviorOfInterestCleversys = 'Social Approach' #cleversys-defined social contact\n",
    "#behaviorOfInterestCleversys = '1 to 2' #cleversys-defined social approach 1 to 2\n",
    "\n",
    "behaviorOfInterestBoris = 'contact investigation' #boris-defined contact investigation\n",
    "#behaviorOfInterestBoris = '' #boris-defined contact investigation\n",
    "\n",
    "\n",
    "Boris1OrCleversys0 = 1\n",
    "plotCells1OrSpikes0 = 0\n",
    "\n",
    "if plotCells1OrSpikes0 == 1:\n",
    "    dataUsed = cellsKept\n",
    "else:\n",
    "    dataUsed = cellsKeptSpikes\n",
    "\n",
    "\n",
    "socialCv = cv[cv.EventType.str.contains(behaviorOfInterestCleversys)]\n",
    "#socialCv = socialCv[(socialCv.LengthinSec > 1)] #limit to >1sec bouts\n",
    "socialCv = socialCv.tail(-1)\n",
    "#print(socialCv)\n",
    "\n",
    "upsampleNovel = 0\n",
    "\n",
    "boris1.rename(columns={'Behavioral category': 'BehavioralCategory'},inplace=True)\n",
    "socialCvBoris = boris1[boris1.Behavior.str.contains(behaviorOfInterestBoris)]\n",
    "socialCvBoris = socialCvBoris[socialCvBoris.Behavior.str.contains(behaviorOfInterestBoris)]\n",
    "#socialCvBoris = socialCvBoris[socialCvBoris.BehavioralCategory.str.contains('Affiliative')]\n",
    "\n",
    "\n",
    "#socialCvBoris = socialCvBoris[(socialCvBoris['Duration (s)'] > 1)]\n",
    "if mainDir == day2:\n",
    "    socialCvBorisNovel = socialCvBoris[socialCvBoris.Subject.str.contains(novel)]\n",
    "    socialCvBorisPartner = socialCvBoris[socialCvBoris.Subject.str.contains(partner)]\n",
    "    if runPartner1OrNovel0==1:\n",
    "        socialCvBoris = socialCvBorisPartner\n",
    "    elif runPartner1OrNovel0==0:\n",
    "        socialCvBoris = socialCvBorisNovel\n",
    "        \n",
    "    upsampleNovel = 1 \n",
    "    #socialCvBoris = socialCvBoris[socialCvBoris.Behavior.str.contains('noncontact')]\n",
    "elif mainDir == day14:\n",
    "    socialCvBoris = socialCvBoris[socialCvBoris.Subject.str.contains(novel)]\n",
    "socialCvBoris = socialCvBoris.tail(-1)\n",
    "if Boris1OrCleversys0==1:\n",
    "    socialCv = socialCvBoris\n",
    "    behaviorOfInterest = behaviorOfInterestBoris\n",
    "\n",
    "numBeforeEvent = 20\n",
    "numAfterEvent = 30\n",
    "numTotal = numBeforeEvent + numAfterEvent\n",
    "socialContactC = np.zeros([dataUsed.shape[0],numTotal,socialCv.shape[0]])\n",
    "print(socialContactC.shape)\n",
    "\n",
    "\n",
    "for ev in range(socialCv.shape[0]):\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameStart = socialCv.iloc[ev,9]\n",
    "    else: \n",
    "        scopeFrameStart = socialCv.iloc[ev,18]\n",
    "        \n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,10]\n",
    "    else:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,19]\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "    #try: #to account for events happening too close to end\n",
    "    socialContactC[:,0:numBeforeEvent-1,ev] = dataUsed.iloc[:,minianFrameStart-numBeforeEvent:minianFrameStart-1]\n",
    "    socialContactC[:,numBeforeEvent-1:numTotal,ev] = dataUsed.iloc[:,minianFrameStart:minianFrameStart+numAfterEvent+1] \n",
    "    #except:\n",
    "        #pass\n",
    "    \n",
    "    \n",
    "#socialContactC = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "#print(socialCvBoris)\n",
    "#socialCvBoris.sum(' Duration (s)')\n",
    "\n",
    "\n",
    "\n",
    "total = socialCvBoris['Duration (s)'].sum()\n",
    "print(total)\n",
    "\n",
    "#socialCvBoris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Assemblies_MEK\n",
    "dataUsedDf = dataUsed.to_numpy()\n",
    "np.shape(dataUsedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edefb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Assemblies_MEK)\n",
    "assembly_dict, fig, axs = Assemblies_MEK.find_assemblies(dataUsedDf,method='ica',nullhyp='mp',n_shuffles=1000,percentile=99,tracywidow=False,\n",
    "                              compute_activity=True, use_bool=False, plot=True)\n",
    "#assembly_dict has patterns, significance, z_data, orig_data, and activations\n",
    "\n",
    "   \n",
    "fileName = mainDirName + 'assemblies_spikes.png'\n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'assemblies/')\n",
    "\n",
    "print(len(assembly_dict['activations']))\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "#fig.savefig(saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68356bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96910732",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = assembly_dict['patterns']\n",
    "activations = assembly_dict['activations']\n",
    "sorted_spiking = assembly_dict['sorted_spiking']\n",
    "sorted_colors = assembly_dict['sorted_colors']\n",
    "\n",
    "print(activations.shape)\n",
    "\n",
    "\n",
    "fig,axs = Assemblies_MEK.plot_assemblies_select(activations, sorted_spiking, colors=sorted_colors)\n",
    "\n",
    "\n",
    "fileName = mainDirName + 'assemblies_spikes_example.png'\n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'assemblies/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "\n",
    "#with open(os.path.join(saveFolder + '\\_5546_day0.pkl'), 'wb') as f:\n",
    "    #pickle.dump([assembly_dict], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6913204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) try warping novel events using nearest neighbor to equalize the num of frames for each event type\n",
    "# 2) using total novel time, subsample partner time & remove other frames\n",
    "\n",
    "import statistics \n",
    "\n",
    "totalSession = boris1['Duration (s)'].sum()\n",
    "#print(totalSession)\n",
    "\n",
    "totalPartner = socialCvBorisPartner['Duration (s)'].sum()\n",
    "totalNovel = socialCvBorisNovel['Duration (s)'].sum()\n",
    "novelTimeToAddTotal = (totalPartner-totalNovel)\n",
    "#print(middlePoint)\n",
    "\n",
    "# divide amount of necessary added time by # events to add that time to\n",
    "#novelTimeToAdd = middlePoint - totalNovel\n",
    "#partnerTimeToSubtract = totalPartner - middlePoint\n",
    "\n",
    "#print(len(socialCvBorisPartner))\n",
    "#print(len(socialCvBorisNovel))\n",
    "novelTimeToAdd = novelTimeToAddTotal / len(socialCvBorisNovel)\n",
    "#partnerTimeToSubtract = partnerTimeToSubtract / len(socialCvBorisPartner)\n",
    "#print(novelTimeToAdd)\n",
    "#print(partnerTimeToSubtract)\n",
    "\n",
    "\n",
    "# find avg conversion between behavior frame #s and minian frame #s. use that \n",
    "differenceFrameNums = socialCvBorisNovel.iloc[:,17] - socialCvBorisNovel.iloc[:,16]\n",
    "differenceScopeNums = socialCvBorisNovel.iloc[:,19] - socialCvBorisNovel.iloc[:,18]\n",
    "avgConversion = np.mean(differenceScopeNums / differenceFrameNums)\n",
    "\n",
    "\n",
    "#bug - newMinianLength changes with every event, so cant be set in stone here\n",
    "#but if I write it back into dataUsed, then the indices for that change..\n",
    "newCell = np.zeros((len(tempData),dataUsed.shape[1]+(novelTimeToAddTotal*avgConversion),socialCvBorisNovel.shape[0]))\n",
    "                   \n",
    "#print(socialCvBorisNovel.shape[0])\n",
    "#print(newMinianLength)\n",
    "\n",
    "for ev in [0]:#range(socialCvBorisNovel.shape[0]):\n",
    "\n",
    "    # pull out cam and scope frame indices\n",
    "    camFrameStart = socialCvBorisNovel.iloc[ev,16]\n",
    "    camFrameStop = socialCvBorisNovel.iloc[ev,17]\n",
    "    scopeFrameStart = socialCvBorisNovel.iloc[ev,18]\n",
    "    scopeFrameEnd = socialCvBorisNovel.iloc[ev,19]\n",
    "\n",
    "    #display(socialCvBorisNovel.iloc[0:5,:])\n",
    "\n",
    "    #convert seconds into frames to add\n",
    "    framesToAdd = novelTimeToAdd * 50\n",
    "    # add new behavior frames. these will become 1s downstream\n",
    "    newEnd = (round(camFrameStop+framesToAdd))\n",
    "    socialCvBorisNovel.iloc[ev,17] = newEnd\n",
    "        # adjust the rest of the frames to account for this change\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,16] = socialCvBorisNovel.iloc[ev+1:-1,16] + int(framesToAdd)\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,17] = socialCvBorisNovel.iloc[ev+1:-1,17] + int(framesToAdd)\n",
    "\n",
    "    # now go into neural data and interpolate to warp equivalent amount of neural data\n",
    "\n",
    "    # find new minianFrameStart and minianFrameEnd\n",
    "    # go into dataUsed and interpolate it, making dataUsed larger\n",
    "    scopeFramesToAdd = int(framesToAdd * avgConversion)\n",
    "    newScopeFrameEnd = scopeFrameEnd + scopeFramesToAdd\n",
    "    socialCvBorisNovel.iloc[ev,19] = newScopeFrameEnd\n",
    "\n",
    "    # adjust the rest of the frames to account for this change\n",
    "    # when indexed in the future, it will ultimately point to a modified dataUsed that has new frames\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,18] = socialCvBorisNovel.iloc[ev+1:-1,18] + int(scopeFramesToAdd)\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,19] = socialCvBorisNovel.iloc[ev+1:-1,19] + int(scopeFramesToAdd)\n",
    "\n",
    "    # get the typical minian frame indices\n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "\n",
    "\n",
    "    # get new minian frame end index, and new length of data\n",
    "    newMinianFrameEnd = round(newScopeFrameEnd / dsFactorUsed)\n",
    "    newMinianLength = newMinianFrameEnd - minianFrameStart\n",
    "    existingMinianLength = minianFrameEnd - minianFrameStart\n",
    "\n",
    "\n",
    "    print(newMinianLength)\n",
    "    print(existingMinianLength)\n",
    "\n",
    "    # pull out the existing data\n",
    "    tempData = dataUsed.iloc[:,minianFrameStart:minianFrameEnd]\n",
    "\n",
    "\n",
    "    #Initialize new numpy matrix for cells with new length of data\n",
    "    newCell = np.zeros((len(tempData),newMinianLength))\n",
    "\n",
    "    # loop through cells\n",
    "    for cell in [0]:#[0]:#range(len(dataUsed)):\n",
    "        #print(cell)\n",
    "        tempDataCell = tempData.iloc[cell,:] \n",
    "\n",
    "\n",
    "        # to determine how many times to repeat Minian values \n",
    "        multiplyFactor = (round(newMinianLength/existingMinianLength))\n",
    "        #print(multiplyFactor)\n",
    "\n",
    "    \n",
    "        tempDataCell = tempDataCell.to_numpy()\n",
    "        tempDataCell = np.repeat(tempDataCell,multiplyFactor+1,axis=0)\n",
    "\n",
    "        #print(newMinianLength)\n",
    "\n",
    "        #now, take out the # of frames that we overshot by\n",
    "        #shitty way to do it\n",
    "        change = (len(tempDataCell) - newMinianLength)\n",
    "        randDelete = random.sample(range(0,len(tempDataCell)),change)\n",
    "        tempDataCell = np.delete(tempDataCell,randDelete)\n",
    "        #print(len(tempDataCell))\n",
    "\n",
    "        # insert into array\n",
    "        newCell[cell,:] = tempDataCell\n",
    "\n",
    "        #tempDataCell  = pd.DataFrame(tempDataCell)\n",
    "        #tempData.iloc[cell,:] = tempDataCell\n",
    "        #dataWriteIn = newCell[cell,0:existingMinianLength]\n",
    "        \n",
    "        \n",
    "        #len(dataWriteIn.columns)\n",
    "        \n",
    "        #dataWriteIn = newCell.reshape((existingMinianLength,))\n",
    "        #dataWriteIn = pd.DataFrame(newCell[cell,0:existingMinianLength])\n",
    "        #dataWriteIn = pd.DataFrame(dataWriteIn)\n",
    "        #dataWriteIn = dataWriteIn.reshape((existingMinianLength,))\n",
    "    dataWriteIn = newCell[:,0:existingMinianLength]\n",
    "    print(dataWriteIn.shape)\n",
    "    dataUsed.iloc[:,minianFrameStart:minianFrameEnd] = dataWriteIn\n",
    "    \n",
    "    print(dataUsed.shape)\n",
    "        \n",
    "    # now for anything beyond existing MinianLength, need to expand the # of columns\n",
    "    numRemaining = newMinianLength - existingMinianLength\n",
    "    remainingData = newCell[:,-numRemaining:]\n",
    "    numSamples = (remainingData.shape[0])\n",
    "    #print(minianFrameEnd+1)\n",
    "    #print(minianFrameEnd+1+numSamples)\n",
    "    #print([minianFrameEnd+1:minianFrameEnd+1+numSamples])\n",
    "    #dataUsed.insert(minianFrameEnd+1:minianFrameEnd+1+remainingData.shape,[],remainingData)\n",
    "    #dataUsed.insert[cell,minianFrameEnd+1,'columns'] = remainingData    \n",
    "    #display(pd.DataFrame(remainingData))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(remainingData.shape)\n",
    "    print(dataUsed.shape)\n",
    "    \n",
    "    \n",
    "    remainingData = pd.DataFrame(remainingData)\n",
    "    unitIdNames = (dataUsed.index)\n",
    "    remainingData.index = unitIdNames\n",
    "    \n",
    "    dataUsed = dataUsed.join(remainingData,rsuffix='_')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(dataUsed)\n",
    "print(remainingData.shape)\n",
    "print(dataWriteIn.shape)\n",
    "print(unitIdNames)\n",
    "\n",
    "#dataUsed2 = dataUsed.join(remainingData,rsuffix='_')\n",
    "#print(dataUsed2.shape)\n",
    "display(dataUsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e489a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## BEHAVIOR SPECIFIC PCA\n",
    "socialContactC_acrossCells = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "socialContactC_acrossCells = socialContactC_acrossCells.transpose()\n",
    "model = pca(n_components=0.95)\n",
    "results = model.fit_transform(socialContactC_acrossCells)\n",
    "fig,ax = model.plot()\n",
    "\n",
    "fileName = mainDirName + 'BehaviorPCA.png'\n",
    "if mainDir == day2:\n",
    "    fileName = mainDirName + 'NovelBehaviorPCA.png'\n",
    "elif mainDir == day14:\n",
    "    fileName = mainDirName + 'PartnerBehaviorPCA.png'\n",
    "    \n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'PCA/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "fig.savefig(saveName)\n",
    "\n",
    "#fig.savefig(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442100dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for running AUC shuffles\n",
    "def auROCshuffle(cellActivity):\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "\n",
    "    # initialize TPR and FPR for each of the 100 steps\n",
    "    TPR_cell = [0] * 100\n",
    "    FPR_cell = [0] * 100\n",
    "\n",
    "    #max(cellActivityZScore)\n",
    "    #min(cellActivityZScore)\n",
    "\n",
    "    # define 100 steps of z-scored DF/F\n",
    "    steps = np.linspace(min(cellActivityZScore),max(cellActivityZScore),num=100)\n",
    "\n",
    "    for st in range(len(steps)):\n",
    "        # iter through steps, calculate metrics, aggregate\n",
    "        indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "        indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for ind in range(len(indices)):\n",
    "            behaviorPresence  = contactBinary[indices[ind]]\n",
    "            if behaviorPresence==1:\n",
    "                TP = TP + 1\n",
    "            if behaviorPresence==0:\n",
    "                FP = FP + 1\n",
    "    \n",
    "        for indBelow in range(len(indicesBelow)):\n",
    "            behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "            if behaviorPresence==1:\n",
    "                FN = FN + 1\n",
    "            if behaviorPresence==0:\n",
    "                TN = TN + 1\n",
    "        #try:\n",
    "        TPR_cell[st] = TP / (TP + FN)\n",
    "        #except:\n",
    "            #sometimes TPR is dividing by 0 b/c at a given threshold, there were no true positives and no false negatives yet\n",
    "            #TPR_cell[st] = 0\n",
    "            #print(st)\n",
    "            #print(ind)\n",
    "        if doPRC==0:\n",
    "            FPR_cell[st] = FP / (FP + TN)\n",
    "        elif doPRC==1:\n",
    "            FPR_cell[st] = TP / (TP + FP) #actually precision\n",
    "\n",
    "    # plot AUCs on top of one another and write out AUC\n",
    "    #plt.plot(FPR_cell,TPR_cell,'b')\n",
    "    if doPRC==1:\n",
    "        AUC_shuffles = auc(TPR_cell,FPR_cell)\n",
    "    elif doPRC==0:\n",
    "        AUC_shuffles = auc(FPR_cell,TPR_cell)\n",
    "    \n",
    "    return AUC_shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cellsKept.shape)\n",
    "print(activations.shape)\n",
    "cellsKept = pd.DataFrame(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f4469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runShuffle = 1\n",
    "doPRC = 1\n",
    "import nn_interpolate\n",
    "\n",
    "#construct binary vector of behavior yes/no\n",
    "contactBinary = [0] * numMinianDownsample\n",
    "\n",
    "from collections import deque\n",
    "from random import randint\n",
    "\n",
    "# go through behaviors, find the minian frames they align to, and assign those as 1s\n",
    "for ev in range(socialCv.shape[0]):\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameStart = socialCv.iloc[ev,9] #this is \n",
    "    else: \n",
    "        scopeFrameStart = socialCv.iloc[ev,18]\n",
    "        \n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,10]\n",
    "    else:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,19]\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "    temp = np.tile(1,minianFrameEnd-minianFrameStart) #vector of 1s\n",
    "    temp = np.ndarray.tolist(temp)\n",
    "    contactBinary[minianFrameStart:minianFrameEnd] = temp #insert 1s into the binary vector\n",
    "\n",
    "\n",
    "#count_1 = contactBinary.count(1)\n",
    "if doPRC==0:\n",
    "    fileName = mainDirName + 'auROC.png'\n",
    "elif doPRC==1:\n",
    "    fileName = mainDirName + 'PRC.png'\n",
    "\n",
    "\n",
    "if mainDir == day2:\n",
    "    if runPartner1OrNovel0==0:\n",
    "        fileName = mainDirName + 'novel_PRC.png'\n",
    "    elif runPartner1OrNovel0==1:\n",
    "        fileName = mainDirName + 'partner_PRC.png' \n",
    "elif mainDir == day14:\n",
    "    fileName = mainDirName + 'novel_PRC.png'\n",
    "    \n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'auROC/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "\n",
    "\n",
    "# initialize AUC vector\n",
    "AUC_cells = [0] * cellsKept.shape[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "#if warp==1, I can change cellsKept into a numpy array that includes mods \n",
    "\n",
    "# iterate through cells\n",
    "for cell in range(cellsKept.shape[0]):\n",
    "    print(cell)\n",
    "    cellNum = cell\n",
    "    cellActivity = cellsKept.iloc[cellNum,:]\n",
    "    cellActivity = cellActivity.tolist()\n",
    "    #print(cellActivity)\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "\n",
    "    # initialize TPR and FPR for each of the 100 steps\n",
    "    TPR_cell = [0] * 100\n",
    "    FPR_cell = [0] * 100\n",
    "\n",
    "    #max(cellActivityZScore)\n",
    "    #min(cellActivityZScore)\n",
    "\n",
    "    # define 100 steps of z-scored DF/F\n",
    "    steps = np.linspace(min(cellActivityZScore),max(cellActivityZScore),num=100)\n",
    "\n",
    "    for st in range(len(steps)):\n",
    "        # iter through steps, calculate metrics, aggregate\n",
    "        indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "        indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for ind in range(len(indices)):\n",
    "            behaviorPresence  = contactBinary[indices[ind]]\n",
    "            if behaviorPresence==1:\n",
    "                TP = TP + 1\n",
    "            if behaviorPresence==0:\n",
    "                FP = FP + 1\n",
    "    \n",
    "        for indBelow in range(len(indicesBelow)):\n",
    "            behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "            if behaviorPresence==1:\n",
    "                FN = FN + 1\n",
    "            if behaviorPresence==0:\n",
    "                TN = TN + 1\n",
    "                \n",
    "                \n",
    "        if doPRC==0:\n",
    "            FPR_cell[st] = FP / (FP + TN)\n",
    "        elif doPRC==1:\n",
    "            FPR_cell[st] = TP / (TP + FP) #actually precision\n",
    "        \n",
    "        #try:\n",
    "        TPR_cell[st] = TP / (TP + FN)\n",
    "        #except:\n",
    "            #need to figure out why a few cells are trying to divide by zero \n",
    "            #TPR_cell[st] = 0\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #print(st)\n",
    "            #print(ind)\n",
    "        #print(TPR_cell[st])\n",
    "        #print(FPR_cell[st])   \n",
    " \n",
    "\n",
    "    # plot AUCs on top of one another and write out AUC\n",
    "    if doPRC==1:\n",
    "        AUC_cells[cell] = auc(TPR_cell,FPR_cell)\n",
    "    elif doPRC==0:\n",
    "        AUC_cells[cell] = auc(FPR_cell,TPR_cell)\n",
    "        \n",
    "        \n",
    "    #AUC_cells[cell] = auc(FPR_cell,TPR_cell)\n",
    "    \n",
    "    if runShuffle==1:    \n",
    "    \n",
    "        AUC_shuffleAll = [0] * 100\n",
    "        items = deque(cellActivity)\n",
    "        for shuffle in range((100)):\n",
    "            #print(shuffle)\n",
    "            items.rotate(randint(0,len(cellActivityZScore)))\n",
    "            shuffledCellActivity = list(items)\n",
    "            AUC_shuffleAll[shuffle] = auROCshuffle(shuffledCellActivity)\n",
    "            #print(AUC_shuffleAll[shuffle])\n",
    "        shufflesNoZeros = [i for i in AUC_shuffleAll if i!= 0]\n",
    "        if doPRC==0:\n",
    "            if AUC_cells[cell] > np.percentile(shufflesNoZeros,97.5):\n",
    "                plt.plot(FPR_cell,TPR_cell,'r')\n",
    "            elif AUC_cells[cell] < np.percentile(shufflesNoZeros,2.5):\n",
    "                plt.plot(FPR_cell,TPR_cell,'r')\n",
    "            else:\n",
    "                plt.plot(FPR_cell,TPR_cell,'b')\n",
    "        elif doPRC==1:\n",
    "            if AUC_cells[cell] > np.percentile(shufflesNoZeros,97.5):\n",
    "                plt.plot(TPR_cell,FPR_cell,'r')\n",
    "            elif AUC_cells[cell] < np.percentile(shufflesNoZeros,2.5):\n",
    "                plt.plot(TPR_cell,FPR_cell,'r')\n",
    "            else:\n",
    "                plt.plot(TPR_cell,FPR_cell,'b')            \n",
    "            \n",
    "    elif runShuffle==0:\n",
    "        \n",
    "        if doPRC==0:\n",
    "            plt.plot(FPR_cell,TPR_cell,'b')\n",
    "        elif doPRC==1:\n",
    "            plt.plot(TPR_cell,FPR_cell,'b')\n",
    "        \n",
    "        \n",
    "if doPRC==1:\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "elif doPRC==0:\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "fig.savefig(saveName)\n",
    "#need a shuffle procedure\n",
    "    \n",
    "#with open(writeOutDir, 'wb') as f:\n",
    "    #pickle.dump([AUC_cells], f)\n",
    "\n",
    "\n",
    "    \n",
    "#temp = np.tile(1,minianFrameEnd-minianFrameStart)\n",
    "#temp = np.ndarray.tolist(temp)\n",
    "#temp\n",
    "#ls = [type(item) for item in temp]\n",
    "#print(ls)\n",
    "#np.tile(1,minianFrameEnd-minianFrameStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db038e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shufflesNoZeros\n",
    "AUC_cells[cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf1533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d28f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=0\n",
    "# iter through steps, calculate metrics, aggregate\n",
    "indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "        \n",
    "for ind in range(len(indices)):\n",
    "    behaviorPresence  = contactBinary[indices[ind]]\n",
    "    if behaviorPresence==1:\n",
    "        TP = TP + 1\n",
    "    if behaviorPresence==0:\n",
    "        FP = FP + 1\n",
    "    \n",
    "for indBelow in range(len(indicesBelow)):\n",
    "    behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "    if behaviorPresence==1:\n",
    "        FN = FN + 1\n",
    "    if behaviorPresence==0:\n",
    "        TN = TN + 1\n",
    "                \n",
    "                \n",
    "print(len(indices))\n",
    "print(TP)\n",
    "print(FN)\n",
    "\n",
    "print(len(indicesBelow))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from random import randint\n",
    "\n",
    "items=deque(cellActivity)\n",
    "items.rotate(randint(0,len(cellActivity)))\n",
    "shuffledCellActivity = list(items)\n",
    "\n",
    "#print(cellActivity[0:5])\n",
    "\n",
    "#items = deque(cellActivity)\n",
    "#shuffleBy = randint(0,len(cellActivity))\n",
    "#print(shuffleBy)\n",
    "    \n",
    "#items.rotate(shuffleBy)\n",
    "\n",
    "#new = list(items)\n",
    "#print(new[0:5])\n",
    "\n",
    "\n",
    "#items.\n",
    "\n",
    "#cellActivity.append(cellActivity.pop(0))\n",
    "\n",
    "#print(cellActivity[0:5])\n",
    "\n",
    "#print(cellActivityShuffled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_shuffleAll = [0] * 100\n",
    "items = deque(cellActivity)\n",
    "for shuffle in range((100)):\n",
    "    items.rotate(randint(0,len(cellActivity)))\n",
    "    shuffledCellActivity = list(items)\n",
    "    AUC_shuffleAll[shuffle] = auROCshuffle(shuffledCellActivity)\n",
    "print(AUC_shuffleAll)\n",
    "if AUC_cells[cell] > np.percentile(AUC_shuffleAll,97.5):\n",
    "    #color it red\n",
    "    elif AUC_cells[cell] < np.percentile(AUC_shuffleAll,2.5):\n",
    "        # color it red\n",
    "    else:\n",
    "        # color it blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_cells[cell] > np.percentile(AUC_shuffleAll,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('computed AUC: {}'.format(auc(FPR_cell,TPR_cell)))\n",
    "\n",
    "with open(os.path.join(writeOutDir + '\\AUC_N.pkl'), 'wb') as f:\n",
    "    pickle.dump([AUC_cells], f)\n",
    "    \n",
    "indexMaxAUC = [i for i in range(len(AUC_cells)) if AUC_cells[i] == max(AUC_cells)]\n",
    "indexMaxAUC\n",
    "\n",
    "ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "openDir0 = os.path.join(mainDir0 + '/analysesOutput/AUC.pkl')\n",
    "openDir1 = os.path.join(mainDir1 + '/analysesOutput/AUC.pkl')\n",
    "openDir2 = os.path.join(mainDir2 + '/analysesOutput/AUC.pkl')\n",
    "\n",
    "with open(openDir0, 'rb') as f:\n",
    "    AUC_0 = pickle.load(f)\n",
    "with open(openDir1, 'rb') as f:\n",
    "    AUC_1 = pickle.load(f)    \n",
    "with open(openDir2, 'rb') as f:\n",
    "    AUC_2 = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(AUC_0,AUC_1,axis=1)\n",
    "\n",
    "#scipy.mean(AUC_0) - scipy.mean(AUC_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "# initialize AUC vector\n",
    "AUC_cells = [0] * cellsKept.shape[0]\n",
    "\n",
    "# iterate through cells\n",
    "for cell in range(cellsKept.shape[0]):\n",
    "    cellNum = cell\n",
    "    cellActivity = cellsKept.iloc[cellNum,:]\n",
    "    cellActivity = cellActivity.tolist()\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(contactBinary, cellActivityZScore)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting by cell\n",
    "\n",
    "figTotal,axTotal = plt.subplots(15,3,figsize=(10,10))\n",
    "for cell in range(socialContactC.shape[0]):\n",
    "    cellActivity = socialContactC[cell,:,:]\n",
    "    socialContactMeans = np.nanmean(cellActivity,axis=1)\n",
    "    socialContactSte = np.nanstd(cellActivity,axis=1)\n",
    "    socialContactSte = socialContactSte / np.sqrt(cellActivity.shape[1])\n",
    "\n",
    "    xval = np.arange(numTotal)\n",
    "    plt.subplot(15,3,cell+1)\n",
    "    plt.errorbar(xval,socialContactMeans,socialContactSte,linestyle='None')\n",
    "    #plt.xlabel('Time relative to social contact (sec)')\n",
    "    #plt.ylabel('DF/F')\n",
    "    plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])\n",
    "    #ax.set_ylim(-0.05, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting across cells\n",
    "socialContactC_acrossCells = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "\n",
    "socialContactMeans = np.nanmedian(socialContactC_acrossCells,axis=0) #across cells\n",
    "socialContactSte = np.nanstd(socialContactC_acrossCells,axis=0)\n",
    "socialContactSte = socialContactSte / np.sqrt(socialContactC_acrossCells.shape[0])\n",
    "\n",
    "\n",
    "xval = np.arange(numTotal)\n",
    "plt.subplot()\n",
    "plt.errorbar(xval,socialContactMeans,socialContactSte,linestyle='None')\n",
    "plt.xlabel('Time relative to social contact (sec)')\n",
    "plt.ylabel('DF/F')\n",
    "plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellNum = 35\n",
    "cellActivity = socialContactC[cellNum,:,:]\n",
    "# plot all 83 traces on one plot\n",
    "\n",
    "xval = np.arange(numTotal)\n",
    "\n",
    "np.shape(cellActivity)\n",
    "for bout in range(cellActivity.shape[1]):\n",
    "    plt.plot(xval,cellActivity[:,bout])\n",
    "    \n",
    "    plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])\n",
    "    plt.xlabel('Time relative to social approach (sec)')\n",
    "    plt.ylabel('DF/F')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
