{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97ce340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"scripts\")  # Add the path to the scripts folder\n",
    "#import script_file_1\n",
    "\n",
    "import h5py\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "573171c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of file_paths to loop over and extract data from \n",
    "sess_dir = 'C:/code/SMTB_2023/imaging/data/5546'\n",
    "\n",
    "save_dir = sess_dir + '/5546_total.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd90dca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_.hdf5'\n",
    "with h5py.File(file_path, 'r') as hdf_file:\n",
    "    print(hdf_file.keys())\n",
    "    print(hdf_file['estimates'].keys())\n",
    "    data = hdf_file['estimates']['C'][:]\n",
    "\n",
    "file_path_write = file_path.replace('.hdf5', '.pkl')\n",
    "with open(file_path_write, 'wb') as file:\n",
    "    pickle.dump(data, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fa559b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RUN TIMESTAMP_CONCAT_ALIGN.IPYNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c6806c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now load both pkls and combine them into one \n",
    "behavior_output_path = sess_dir + '/forCaiman.pkl'\n",
    "with open(behavior_output_path, 'rb') as file:\n",
    "    cv, boris1 = pickle.load(file)\n",
    "with open(file_path_write, 'rb') as file:\n",
    "    C_array = pickle.load(file)\n",
    "\n",
    "    \n",
    "file_path_total = file_path_write.replace('.pkl', 'total.pkl')\n",
    "with open(file_path_total, 'wb') as f:\n",
    "    pickle.dump([C_array, cv, boris1], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e0c9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##LOAD DATA\n",
    "\n",
    "\n",
    "files_to_analyze = ['C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_total.pkl']\n",
    "with open(files_to_analyze[0], 'rb') as file:\n",
    "    C_array, cv, boris1 = pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4f4e85d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store data from multiple files\n",
    "C_arrays = []\n",
    "cvs = []\n",
    "boris1s = []\n",
    "\n",
    "# List of files to analyze\n",
    "files_to_analyze = ['C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_total.pkl',\n",
    "                    'C:/code/SMTB_2023/imaging/data/5546/day0_corr08_pnr5_total.pkl']\n",
    "\n",
    "# Loop through files and store the data\n",
    "for file_path in files_to_analyze:\n",
    "    with open(file_path, 'rb') as file:\n",
    "        C_array, cv, boris1 = pickle.load(file)\n",
    "        C_arrays.append(C_array)\n",
    "        cvs.append(cv)\n",
    "        boris1s.append(boris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adee6c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_arrays[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59b541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ce94a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(boris1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21e50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boris1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c3a27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "boris1['Behavior'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "456c3da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(boris1.scopeFrameEnd.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ae5cf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08489556",
   "metadata": {},
   "outputs": [],
   "source": [
    "107204 / 53613"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bebe12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def visualize_2D_matrix_with_shading(matrix, behavior_df, behavior_name, default_vmax=1.0):\n",
    "    def update_plot(colormap, vmin, vmax):\n",
    "        clear_output(wait=True)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        plt.imshow(matrix, cmap=colormap, vmin=vmin, vmax=vmax, aspect='auto')\n",
    "        plt.colorbar()\n",
    "        plt.title(\"One-Photon Calcium Imaging 2D Matrix\")\n",
    "        plt.xlabel(\"Time\")\n",
    "        plt.ylabel(\"Neurons\")\n",
    "        \n",
    "        # Get 'scopeFrameStart' and 'scopeFrameEnd' values for the specified behavior name\n",
    "        behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "        start_frames = behavior_data['scopeFrameStart'].values\n",
    "        end_frames = behavior_data['scopeFrameEnd'].values\n",
    "        \n",
    "        # Plot shaded regions for 'scopeFrameStart' and 'scopeFrameEnd'\n",
    "        for start_frame, end_frame in zip(start_frames, end_frames):\n",
    "            plt.axvspan(start_frame, end_frame, color='lightblue', alpha=0.6)\n",
    "        \n",
    "        plt.show()\n",
    "\n",
    "    # Define interactive widgets (same as before)\n",
    "    colormap_selector = widgets.Dropdown(\n",
    "        options=['viridis', 'plasma', 'inferno', 'magma', 'cividis'],\n",
    "        value='viridis',\n",
    "        description='Colormap:',\n",
    "    )\n",
    "\n",
    "    vmin_slider = widgets.FloatSlider(\n",
    "        value=np.min(matrix),\n",
    "        min=np.min(matrix),\n",
    "        max=np.max(matrix),\n",
    "        step=0.1,\n",
    "        description='Min Value:',\n",
    "    )\n",
    "    \n",
    "    vmax_slider = widgets.FloatSlider(\n",
    "        value=default_vmax,\n",
    "        min=np.min(matrix),\n",
    "        max=np.max(matrix),\n",
    "        step=0.1,\n",
    "        description='Max Value:',\n",
    "    )\n",
    "\n",
    "    # Create the interactive plot (same as before)\n",
    "    interactive_plot = widgets.interactive(\n",
    "        update_plot,\n",
    "        colormap=colormap_selector,\n",
    "        vmin=vmin_slider,\n",
    "        vmax=vmax_slider,  # Using the checkbox value directly for vmax_auto\n",
    "    )\n",
    "\n",
    "    display(interactive_plot)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76150a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0ea233",
   "metadata": {},
   "outputs": [],
   "source": [
    "default_vmax = 10.0\n",
    "for C_array, boris1 in zip(C_arrays, boris1s):\n",
    "    visualize_2D_matrix_with_shading(C_array, boris1, 'mount', default_vmax=10)\n",
    "    \n",
    "#visualize_2D_matrix_with_shading(C_arrays[0], boris1[0], 'mount', default_vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4547fccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transient_timestamps(\n",
    "    neural_data, thresh_type=\"eps\", do_zscore=True, std_thresh=5\n",
    "):\n",
    "    \"\"\"\n",
    "    Converts an array of continuous time series (e.g., traces or S)\n",
    "    into lists of timestamps where activity exceeds some threshold.\n",
    "\n",
    "    :parameters\n",
    "    ---\n",
    "    neural_data: (neuron, time) array\n",
    "        Neural time series, (e.g., C or S).\n",
    "\n",
    "    std_thresh: float\n",
    "        Number of standard deviations above the mean to define threshold.\n",
    "\n",
    "    :returns\n",
    "    ---\n",
    "    event_times: list of length neuron\n",
    "        Each entry in the list contains the timestamps of a neuron's\n",
    "        activity.\n",
    "\n",
    "    event_mags: list of length neuron\n",
    "        Event magnitudes.\n",
    "\n",
    "    \"\"\"\n",
    "    # Compute thresholds for each neuron.\n",
    "    neural_data = np.asarray(neural_data, dtype=np.float32)\n",
    "    if thresh_type == \"eps\":\n",
    "        thresh = np.repeat(np.finfo(np.float32).eps, neural_data.shape[0])\n",
    "    else:\n",
    "        if do_zscore:\n",
    "            stds = np.std(neural_data, axis=1)\n",
    "            #print(stds.shape)\n",
    "            means = np.mean(neural_data, axis=1)\n",
    "            thresh = means + std_thresh * stds\n",
    "        else:\n",
    "            thresh = np.repeat(std_thresh, neural_data.shape[0])\n",
    "\n",
    "    # Get event times and magnitudes.\n",
    "    bool_arr = neural_data > np.tile(thresh, [neural_data.shape[1], 1]).T\n",
    "\n",
    "    event_times = [np.where(neuron > t)[0] for neuron, t in zip(neural_data, thresh)]\n",
    "\n",
    "    event_mags = [neuron[neuron > t] for neuron, t in zip(neural_data, thresh)]\n",
    "\n",
    "    return event_times, event_mags, bool_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daace01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## ANALYSIS IDEA - lets include multiple 'algorithms' here to define our binary in different ways\n",
    "#1- not only does the value have to be above the thresh, but it also has to be greater than the \n",
    "#value before and after it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2143a2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert to boolean\n",
    "# List to store data from multiple files\n",
    "events = []\n",
    "magnitudes = []\n",
    "bool_arr = []\n",
    "\n",
    "# Loop through files and store the data\n",
    "for C_array in C_arrays:\n",
    "    event_single, magnitude_single, bool_single = get_transient_timestamps(C_array, thresh_type='zscore', std_thresh=5)\n",
    "    events.append(event_single)\n",
    "    magnitudes.append(magnitude_single)\n",
    "    bool_arr.append(bool_single)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd24abe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c831c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "bool_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728b49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize_2D_matrix_with_shading(bool_arr, boris1, '', default_vmax=1)\n",
    "\n",
    "for bool_single in bool_arr:\n",
    "    visualize_2D_matrix_with_shading(bool_single, boris1, 'mount', default_vmax=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a69b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_time_locked_responses(matrix, behavior_df, behavior_name, window_before_sec=1, window_after_sec=1, frame_rate=15):\n",
    "    # Convert time windows from seconds to frames\n",
    "    window_before_frames = int(window_before_sec * frame_rate)\n",
    "    window_after_frames = int(window_after_sec * frame_rate)\n",
    "\n",
    "    # Get the behavior data for the specified behavior name\n",
    "    behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "    behavior_start_frame = behavior_data['scopeFrameStart'].values[0]\n",
    "    behavior_end_frame = behavior_data['scopeFrameEnd'].values[0]\n",
    "\n",
    "    # Calculate the view start and view end based on the specified window_before_frames and window_after_frames\n",
    "    view_start = behavior_start_frame - window_before_frames\n",
    "    view_end = behavior_end_frame + window_after_frames\n",
    "\n",
    "    clear_output(wait=True)\n",
    "    plt.close()  # Close the previous figure\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # Calculate the time points relative to the behavior event in seconds\n",
    "    time_points = np.linspace(-window_before_sec, window_after_sec, view_end - view_start + 1)\n",
    "\n",
    "    # Extract the time-locked responses for all cells\n",
    "    time_locked_responses = matrix[:, view_start:view_end + 1]\n",
    "\n",
    "    # Calculate mean and standard deviation across all cells for each time point\n",
    "    mean_response = np.median(time_locked_responses, axis=0)\n",
    "    std_response = np.std(time_locked_responses, axis=0)\n",
    "\n",
    "    # Plot mean and standard deviation\n",
    "    plt.plot(time_points, mean_response, color='b', lw=2, label='Mean')\n",
    "    plt.fill_between(time_points, mean_response - std_response, mean_response + std_response,\n",
    "                     color='b', alpha=0.3, label='Standard Deviation')\n",
    "\n",
    "    plt.axvline(0, color='gray', linestyle='--', alpha=0.5)  # Vertical line at behavior event\n",
    "\n",
    "    plt.title(f\"Time-Locked Responses to Behavior: {behavior_name}\")\n",
    "    plt.xlabel(\"Time Relative to Behavior Event (seconds)\")\n",
    "    plt.ylabel(\"Calcium DF/F\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb75d916",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_rate = 15\n",
    "window_before_sec = 2\n",
    "window_after_sec = 2\n",
    "plot_time_locked_responses(C_array, boris1, 'noncontact investigation',window_before_sec, window_after_sec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323d1d51",
   "metadata": {},
   "outputs": [],
   "source": [
    "##CLICK THROUGH NEURONS TIME LOCKED TO BEHAVIOR, STERROR ACROSS TRIALS\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "def plot_neuron_response(matrix, behavior_df, behavior_name, frames_before=30, frames_after=30):\n",
    "    # Filter the DataFrame based on the specified behavior name\n",
    "    behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "    \n",
    "    if behavior_data.empty:\n",
    "        print(f\"No data found for behavior '{behavior_name}'.\")\n",
    "        return\n",
    "\n",
    "    # Extract the start and end frames for the specified behavior\n",
    "    start_frames = behavior_data['scopeFrameStart'].values\n",
    "\n",
    "    # Calculate the time points relative to the behavior event\n",
    "    time_points = np.arange(-frames_before, frames_after + 1)\n",
    "\n",
    "    # Calculate the time-locked responses for each neuron\n",
    "    time_locked_responses = []\n",
    "    for start_frame in start_frames:\n",
    "        response_start = max(start_frame - frames_before, 0)\n",
    "        response_end = min(start_frame + frames_after + 1, matrix.shape[1])\n",
    "        response = matrix[:, response_start:response_end]\n",
    "        response_padded = np.pad(response, ((0, 0), (max(0, frames_before - (start_frame - response_start)),\n",
    "                                                 max(0, frames_after - (response_end - start_frame)))), \n",
    "                                 mode='constant', constant_values=np.nan)\n",
    "        time_locked_responses.append(response_padded)\n",
    "\n",
    "    if not time_locked_responses:\n",
    "        print(f\"No valid time-locked responses found for behavior '{behavior_name}'.\")\n",
    "        return\n",
    "\n",
    "    # Calculate mean and standard deviation across all trials for each neuron\n",
    "    mean_response = np.nanmedian(time_locked_responses, axis=0)\n",
    "    std_response = np.nanstd(time_locked_responses, axis=0) / np.sqrt(len(time_locked_responses))\n",
    "\n",
    "\n",
    "    # Create an interactive plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "   # Initialize the plot with the first neuron\n",
    "    neuron_idx = 0\n",
    "    line_mean, = ax.plot(time_points, mean_response[neuron_idx], label=f'Neuron {neuron_idx + 1}')\n",
    "    ax.axvline(0, color='gray', linestyle='--', alpha=0.5)  # Vertical line at behavior onset\n",
    "    ax.set_title(f\"Mean and Standard Deviation of Neuron Responses to Behavior: '{behavior_name}'\")\n",
    "    ax.set_xlabel(\"Time Relative to Behavior Onset (Frames)\")\n",
    "    ax.set_ylabel(\"Neuron Response\")\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "    def update_plot(neuron_idx):\n",
    "        ax.clear()\n",
    "        ax.scatter(time_points, mean_response[neuron_idx], label=f'Neuron {neuron_idx + 1}')\n",
    "        ax.fill_between(time_points, mean_response[neuron_idx] - std_response[neuron_idx],\n",
    "                    mean_response[neuron_idx] + std_response[neuron_idx], alpha=0.3)\n",
    "        ax.set_title(f\"Mean and Standard Deviation of Neuron Responses to Behavior: '{behavior_name}'\")\n",
    "        ax.set_xlabel(\"Time Relative to Behavior Onset (Frames)\")\n",
    "        ax.set_ylabel(\"Neuron Response\")\n",
    "        update_legend(neuron_idx)\n",
    "        ax.figure.canvas.draw()\n",
    "\n",
    "    def update_legend(neuron_idx):\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        label = f'Neuron {neuron_idx + 1}'\n",
    "        if label not in labels:\n",
    "            handles.append(line_mean)\n",
    "            labels.append(label)\n",
    "        ax.legend(handles, labels)\n",
    "\n",
    "    # Function to handle the key press event and update the neuron index\n",
    "    def on_key(event):\n",
    "        nonlocal neuron_idx\n",
    "        if event.key == 'right':\n",
    "            neuron_idx = min(neuron_idx + 1, matrix.shape[0] - 1)\n",
    "        elif event.key == 'left':\n",
    "            neuron_idx = max(neuron_idx - 1, 0)\n",
    "        update_plot(neuron_idx)\n",
    "\n",
    "    # Connect the update_plot function to the key press event\n",
    "    fig.canvas.mpl_connect('key_press_event', on_key)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57fa88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "plot_neuron_response(C_array, boris1, 'noncontact investigation')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd78fdbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Now lets feed in C_array, boris1, and a list of all behaviors we want analyzed, with a prestim window and\n",
    "#a poststim window.\n",
    "#inside the function, t-test post vs pre, and a return a binary matrix of cells x behaviors\n",
    "#then a second function can plot a labeled pie chart of neuronal responses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e8d75ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_rel\n",
    "\n",
    "def find_significant_neurons(C_array, behavior_df, behavior_names, prestim_frames, poststim_frames, pvalueIn=0.01):\n",
    "    # Initialize the output matrix\n",
    "    num_neurons = C_array.shape[0]\n",
    "    num_behaviors = len(behavior_names)\n",
    "    significant_neurons = np.zeros((num_neurons, num_behaviors), dtype=int)\n",
    "    behaviors_out = behavior_names\n",
    "    # Loop through neurons and behaviors\n",
    "    for neuron_idx in range(num_neurons):\n",
    "        for behavior_idx, behavior_name in enumerate(behavior_names):\n",
    "            # Filter the DataFrame based on the specified behavior name\n",
    "            behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "\n",
    "            if behavior_data.empty:\n",
    "                print(f\"No data found for behavior '{behavior_name}'.\")\n",
    "                continue\n",
    "\n",
    "            # Extract the start frames for the specified behavior\n",
    "            start_frames = behavior_data['scopeFrameStart'].values\n",
    "\n",
    "            # Calculate the prestimulus and poststimulus time points relative to the behavior event\n",
    "            prestim_time_points = np.arange(-prestim_frames, 0)\n",
    "            poststim_time_points = np.arange(1, poststim_frames + 1)\n",
    "\n",
    "            # Align neuron's activity to the onset of each behavior and calculate prestimulus and poststimulus averages\n",
    "            prestim_trials = []\n",
    "            poststim_trials = []\n",
    "            for start_frame in start_frames:\n",
    "                prestim_start = max(start_frame - prestim_frames, 0)\n",
    "                prestim_end = start_frame\n",
    "                prestim_trials.append(C_array[neuron_idx, prestim_start:prestim_end])\n",
    "\n",
    "                poststim_start = start_frame + 1\n",
    "                poststim_end = min(start_frame + poststim_frames + 1, C_array.shape[1])\n",
    "                poststim_trials.append(C_array[neuron_idx, poststim_start:poststim_end])\n",
    "\n",
    "            # Calculate mean prestimulus and poststimulus responses across trials\n",
    "            #pdb.set_trace()\n",
    "            mean_prestim = np.median(prestim_trials, axis=1)\n",
    "           # print(mean_prestim)\n",
    "            mean_poststim = np.median(poststim_trials, axis=1)\n",
    "           # print(mean_poststim)\n",
    "\n",
    "            # Perform a paired t-test to compare poststimulus vs prestimulus activity\n",
    "            _, p_value = ttest_rel(mean_poststim, mean_prestim)\n",
    "\n",
    "            # Set the value in the output matrix based on the significance level (p < 0.05)\n",
    "            if p_value < pvalueIn:\n",
    "                significant_neurons[neuron_idx, behavior_idx] = 1\n",
    "\n",
    "    return significant_neurons, behaviors_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8753f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviorsToAnalyze = ['noncontact investigation', 'grooming', 'lunge or bite',\n",
    "       'contact investigation', 'mount', 'intromission', 'ejaculation']\n",
    "\n",
    "significant_neurons_data, behaviors_out = find_significant_neurons(C_array, boris1, behaviorsToAnalyze, 15, 30, pvalueIn=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d4c77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "behaviors_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4b476",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_behavior_bar_charts(significant_neurons_data, behaviors_out):\n",
    "    # Calculate the percentage of neurons with 1s for each behavior\n",
    "    percentages = np.mean(significant_neurons_data, axis=0) * 100\n",
    "\n",
    "    # Plot a separate bar chart for each behavior\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.bar(behaviors_out, percentages, color='tab:blue', alpha=0.7)\n",
    "    plt.xlabel('Behaviors')\n",
    "    plt.ylabel('Percentage of Responsive Neurons (%)')\n",
    "    plt.title('Percentage of Neurons Responsive to Each Behavior')\n",
    "    plt.grid(axis='y')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.ylim([0, 50])\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e30922a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_behavior_bar_charts(significant_neurons_data, behaviors_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03cc3b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "def plot_one_row_with_shading(matrix_row, behavior_df, behavior_name):\n",
    "    # Filter the behavior DataFrame for the specified behavior name\n",
    "    behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "    start_frames = behavior_data['scopeFrameStart'].values\n",
    "    end_frames = behavior_data['scopeFrameEnd'].values\n",
    "\n",
    "    # Create the plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 4))\n",
    "    ax.plot(np.arange(len(matrix_row)), matrix_row, color='b', lw=2, label='Signal')\n",
    "\n",
    "    # Add shading for the specified behavior intervals\n",
    "    for start_frame, end_frame in zip(start_frames, end_frames):\n",
    "        ax.axvspan(start_frame, end_frame, alpha=0.3, color='yellow', label=behavior_name)\n",
    "\n",
    "    ax.axhline(0, color='gray', linestyle='--', alpha=0.5)  # Horizontal line at y=0\n",
    "\n",
    "    ax.set_title(\"One-Row Plot with Shading\")\n",
    "    ax.set_xlabel(\"Time (in 10 min intervals)\")\n",
    "    ax.set_ylabel(\"Signal\")\n",
    "    ax.grid(True)\n",
    "    # Set x-axis ticks at seconds intervals\n",
    "\n",
    "    seconds_tick_interval = 9000  # Set the interval for seconds\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(base=seconds_tick_interval))\n",
    "    ax.set_xticklabels([0, 0, 10, 20, 30, 40, 50, 60])\n",
    "    \n",
    "    #ax.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb30eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6efbd6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "row_to_plot = 3\n",
    "plot_one_row_with_shading(C_array[row_to_plot,:], boris1, 'noncontact investigation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1541616e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2616cf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Lets save a pickle file with everything we want for this animal\n",
    "\n",
    "with open(save_dir, 'wb') as file:\n",
    "    pickle.dump([significant_neurons_data, behaviors_out], file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1977f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Analysis idea - lets separate non-contact and contact by investigating or receiving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5772215c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.3.0-cp311-cp311-win_amd64.whl (9.2 MB)\n",
      "                                              0.0/9.2 MB ? eta -:--:--\n",
      "                                              0.0/9.2 MB ? eta -:--:--\n",
      "                                              0.0/9.2 MB 393.8 kB/s eta 0:00:24\n",
      "                                              0.2/9.2 MB 1.6 MB/s eta 0:00:06\n",
      "     ------------------                       4.2/9.2 MB 24.3 MB/s eta 0:00:01\n",
      "     ----------------------------------       8.0/9.2 MB 36.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 9.2/9.2 MB 36.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ephys\\miniconda3\\envs\\scratch\\lib\\site-packages (from scikit-learn) (1.25.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ephys\\miniconda3\\envs\\scratch\\lib\\site-packages (from scikit-learn) (1.11.1)\n",
      "Collecting joblib>=1.1.1 (from scikit-learn)\n",
      "  Downloading joblib-1.3.1-py3-none-any.whl (301 kB)\n",
      "                                              0.0/302.0 kB ? eta -:--:--\n",
      "     ---------------------------------------- 302.0/302.0 kB ? eta 0:00:00\n",
      "Collecting threadpoolctl>=2.0.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.3.1 scikit-learn-1.3.0 threadpoolctl-3.2.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "706b8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def calculate_auROC(matrix, behavior_df, behaviors_to_filter):\n",
    "    # Create an empty matrix to store the auROC values\n",
    "    num_neurons = matrix.shape[0]\n",
    "    num_behaviors = len(behaviors_to_filter)\n",
    "    auROC_matrix = np.zeros((num_neurons, num_behaviors))\n",
    "\n",
    "    # Loop through each neuron and behavior to calculate auROC\n",
    "    for neuron_idx in range(num_neurons):\n",
    "        for behavior_idx, behavior_name in enumerate(behaviors_to_filter):\n",
    "            # Filter the DataFrame based on the specified behavior name\n",
    "            behavior_data = behavior_df[behavior_df['Behavior'] == behavior_name]\n",
    "            if behavior_data.empty:\n",
    "                print(f\"No data found for behavior '{behavior_name}'.\")\n",
    "                continue\n",
    "\n",
    "            # Extract the start and end frames for the specified behavior\n",
    "            start_frames = behavior_data['scopeFrameStart'].values\n",
    "\n",
    "            # Create an array to store the true labels and predicted probabilities for the behavior\n",
    "            true_labels = np.zeros(matrix.shape[1])\n",
    "            predicted_probabilities = np.zeros(matrix.shape[1])\n",
    "\n",
    "            # Set the true labels to 1 for the frames within the behavior window\n",
    "            for start_frame in start_frames:\n",
    "                behavior_start = max(start_frame, 0)\n",
    "                behavior_end = min(start_frame + 1, matrix.shape[1])\n",
    "                true_labels[behavior_start:behavior_end] = 1\n",
    "\n",
    "            # Set the predicted probabilities to be the neuron's responses\n",
    "            predicted_probabilities = matrix[neuron_idx]\n",
    "\n",
    "            # Calculate the auROC for the current neuron and behavior\n",
    "            auROC = roc_auc_score(true_labels, predicted_probabilities)\n",
    "            auROC_matrix[neuron_idx, behavior_idx] = auROC\n",
    "\n",
    "    return auROC_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bf7bcf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bdb7aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have 'matrix', 'behavior_df', and 'behaviors_to_filter' defined\n",
    "auROC_matrix = calculate_auROC(C_arrays[0], boris1s[0], ['noncontact investigation', ''])\n",
    "\n",
    "\n",
    "#print(auROC_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e166e3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.51794189],\n",
       "       [0.53439001],\n",
       "       [0.48832721],\n",
       "       [0.48092551],\n",
       "       [0.55958999],\n",
       "       [0.49252542],\n",
       "       [0.53117741],\n",
       "       [0.5082739 ],\n",
       "       [0.5216327 ],\n",
       "       [0.54918269],\n",
       "       [0.51428566],\n",
       "       [0.51411004],\n",
       "       [0.51962206],\n",
       "       [0.50859024],\n",
       "       [0.53443062],\n",
       "       [0.50727385],\n",
       "       [0.4850703 ],\n",
       "       [0.5031944 ],\n",
       "       [0.46073893],\n",
       "       [0.50170371],\n",
       "       [0.5267594 ],\n",
       "       [0.52444918],\n",
       "       [0.47745086],\n",
       "       [0.52482534],\n",
       "       [0.55344454],\n",
       "       [0.44998328],\n",
       "       [0.51246357],\n",
       "       [0.51229837],\n",
       "       [0.53939344],\n",
       "       [0.48494301],\n",
       "       [0.47812415],\n",
       "       [0.54056509],\n",
       "       [0.51554254],\n",
       "       [0.49260771],\n",
       "       [0.47433461],\n",
       "       [0.52926488],\n",
       "       [0.54011123],\n",
       "       [0.51977653],\n",
       "       [0.55577233],\n",
       "       [0.53101234],\n",
       "       [0.47122005],\n",
       "       [0.57735595],\n",
       "       [0.51941292],\n",
       "       [0.51448726],\n",
       "       [0.48171271],\n",
       "       [0.52617398],\n",
       "       [0.50664381],\n",
       "       [0.48609878],\n",
       "       [0.53179308],\n",
       "       [0.47982303],\n",
       "       [0.4950631 ],\n",
       "       [0.57407675],\n",
       "       [0.60172711],\n",
       "       [0.49268905],\n",
       "       [0.49216283],\n",
       "       [0.50249694],\n",
       "       [0.46185215]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auROC_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bac443",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75e679f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c7cbc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1aee15",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import pdb #for debugging\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "from sklearn.metrics import auc\n",
    "import pickle\n",
    "import holoviews as hv\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import random\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "# ideally loop through multiple directories, load variables into single object per animal,\n",
    "# and then have core functions to loop the objects through, with a plotter that\n",
    "# pulls the outputs together \n",
    "\n",
    "\n",
    "day0 = \"C://miniscopeData/5546/2022_12_15/13_56_20_record/12152022_cohabitation_5546\"\n",
    "day1 = \"C://miniscopeData/5546/2022_12_16/14_36_12/121622_cohousing_5546\"\n",
    "day2 = \"C://miniscopeData/5546/2022_12_17/12_48_22\"\n",
    "partner=\"Left\"\n",
    "novel=\"Right\"\n",
    "runPartner1OrNovel0 = 0\n",
    "\n",
    "day14 = \"C://miniscopeData/5546/2023_01_01/13_17_27/01012023_PPTnodrug\"\n",
    "partnerDay14=\"Right\"\n",
    "novelDay14=\"Left\"\n",
    "\n",
    "\n",
    "mainDir = day0\n",
    "mainDirName = 'day0'\n",
    "\n",
    "loadDir = os.path.join(mainDir + '/alignerOutput')\n",
    "\n",
    "\n",
    "generalOutDir = \"C://miniscopeData/5546\"\n",
    "writeOutDir = os.path.join(generalOutDir + '/analysesOutput')\n",
    "isExist = os.path.exists(writeOutDir)\n",
    "if not isExist:\n",
    "    os.makedirs(writeOutDir)\n",
    "\n",
    "\n",
    "\n",
    "with open(os.path.join(loadDir + '/minianOut.pkl'), 'rb') as f:\n",
    "    cellsKept, cellsKeptSpikes, cv,boris1 = pickle.load(f)\n",
    "    \n",
    "#cellsKept, cellsKeptSpikes, cv, boris1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d14cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scratch cell, to look at downsampling of Minian, to make sure indices are appropriate\n",
    "#temporal downsampling by 2 on Minian, so this should also be 2\n",
    "#also transposes for corr matrix and PCA cells\n",
    "\n",
    "columnNames = cellsKept.columns\n",
    "numMinianFrames = max(columnNames)\n",
    "numMinianDownsample = cellsKept.shape[1]\n",
    "\n",
    "downsampleFactor = numMinianFrames / numMinianDownsample\n",
    "print(downsampleFactor)\n",
    "\n",
    "dsFactorUsed = 2\n",
    "\n",
    "#print(numMinianFrames)\n",
    "\n",
    "cellsKept.shape[0]\n",
    "cellsTransposed = cellsKept.transpose()\n",
    "\n",
    "\n",
    "#print(cellsKept.shape[1])\n",
    "#cellsKept.iloc[(cellsKept['frame']-32).abs().argsort()[:1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5ca63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellsKept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9218c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CORR MATRIX ACROSS SESSION\n",
    "\n",
    "import seaborn as sns \n",
    "#print(cellsTransposed)\n",
    "matrix = cellsTransposed.corr()\n",
    "mask_ut = np.triu(np.ones(matrix.shape)).astype(bool)\n",
    "fig = plt.figure()\n",
    "hmap = sns.heatmap(matrix,mask=mask_ut,vmin=-1,vmax=1,cmap=\"Spectral\")\n",
    "\n",
    "fileName = mainDirName + 'overallCorrMatrix.png'\n",
    "saveFolder = os.path.join(writeOutDir,'corrMatrix/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "fig.savefig(saveName)\n",
    "\n",
    "#print(matrix)\n",
    "#plt.matshow(matrix)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a63cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(X):\n",
    "    # X: ndarray, shape (n_features, n_samples)\n",
    "    ss = StandardScaler(with_mean=True, with_std=True)\n",
    "    Xz = ss.fit_transform(X.T).T\n",
    "    return Xz\n",
    "\n",
    "cellsKept = z_score(cellsKept)\n",
    "\n",
    "print(cellsKept.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03edc555",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA ACROSS SESSION\n",
    "\n",
    "#pip install pca\n",
    "\n",
    "from pca import pca\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "  \n",
    "    \n",
    "def center(X):\n",
    "    # X: ndarray, shape (n_features, n_samples)\n",
    "    ss = StandardScaler(with_mean=True, with_std=False)\n",
    "    Xc = ss.fit_transform(X.T).T\n",
    "    return Xc\n",
    "\n",
    "\n",
    "#cellsKeptCentered = center(cellsTransposed)\n",
    "#cellsKeptCenteredTransposed = cellsKeptCentered.transpose()\n",
    "\n",
    "\n",
    "\n",
    "model = pca(n_components=0.99, normalize=True)\n",
    "results = model.fit_transform(cellsTransposed)\n",
    "fig,ax = model.plot()\n",
    "\n",
    "# Make scatterplot\n",
    "#model.scatter()\n",
    "\n",
    "# Gradient over the samples. High dense areas will be more colourful.\n",
    "#model.scatter(gradient='#FFFFFF')\n",
    "\n",
    "# Include the outlier detection\n",
    "#model.scatter(SPE=True)\n",
    "\n",
    "# Include the outlier detection\n",
    "#model.scatter(hotellingt2=True)\n",
    "\n",
    "# Look at different PCs: 1st PC=1  vs PC=3\n",
    "#model.scatter(PC=[0, 2])\n",
    "\n",
    "#fileName = mainDirName + 'overallPCA.png'\n",
    "#saveFolder = os.path.join(writeOutDir,'PCA/')\n",
    "\n",
    "#isExist = os.path.exists(saveFolder)\n",
    "#if not isExist:\n",
    "#    os.makedirs(saveFolder)\n",
    "    \n",
    "#saveName = saveFolder + fileName\n",
    "#fig.savefig(saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9cc951e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def runPCA(matrixIn,directory):\n",
    "    model = pca(n_components=0.95)\n",
    "    results = model.fit_transform(matrixIn)\n",
    "    fig,ax = model.plot()\n",
    "    fig.savefig(directory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32be000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "boris1.Behavior\n",
    "behaviorUniques = list(set([car for car in boris1.Behavior]))\n",
    "behaviorUniques\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## optional cell for warping behavior and neural data to accomodate equal event totals\n",
    "\n",
    "# modify boris1. \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caea0fc6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#pulling out events and corresponding data \n",
    "\n",
    "behaviorOfInterestCleversys = 'Social Approach' #cleversys-defined social contact\n",
    "#behaviorOfInterestCleversys = '1 to 2' #cleversys-defined social approach 1 to 2\n",
    "\n",
    "behaviorOfInterestBoris = 'contact investigation' #boris-defined contact investigation\n",
    "#behaviorOfInterestBoris = '' #boris-defined contact investigation\n",
    "\n",
    "\n",
    "Boris1OrCleversys0 = 1\n",
    "plotCells1OrSpikes0 = 0\n",
    "\n",
    "if plotCells1OrSpikes0 == 1:\n",
    "    dataUsed = cellsKept\n",
    "else:\n",
    "    dataUsed = cellsKeptSpikes\n",
    "\n",
    "\n",
    "socialCv = cv[cv.EventType.str.contains(behaviorOfInterestCleversys)]\n",
    "#socialCv = socialCv[(socialCv.LengthinSec > 1)] #limit to >1sec bouts\n",
    "socialCv = socialCv.tail(-1)\n",
    "#print(socialCv)\n",
    "\n",
    "upsampleNovel = 0\n",
    "\n",
    "boris1.rename(columns={'Behavioral category': 'BehavioralCategory'},inplace=True)\n",
    "socialCvBoris = boris1[boris1.Behavior.str.contains(behaviorOfInterestBoris)]\n",
    "socialCvBoris = socialCvBoris[socialCvBoris.Behavior.str.contains(behaviorOfInterestBoris)]\n",
    "#socialCvBoris = socialCvBoris[socialCvBoris.BehavioralCategory.str.contains('Affiliative')]\n",
    "\n",
    "\n",
    "#socialCvBoris = socialCvBoris[(socialCvBoris['Duration (s)'] > 1)]\n",
    "if mainDir == day2:\n",
    "    socialCvBorisNovel = socialCvBoris[socialCvBoris.Subject.str.contains(novel)]\n",
    "    socialCvBorisPartner = socialCvBoris[socialCvBoris.Subject.str.contains(partner)]\n",
    "    if runPartner1OrNovel0==1:\n",
    "        socialCvBoris = socialCvBorisPartner\n",
    "    elif runPartner1OrNovel0==0:\n",
    "        socialCvBoris = socialCvBorisNovel\n",
    "        \n",
    "    upsampleNovel = 1 \n",
    "    #socialCvBoris = socialCvBoris[socialCvBoris.Behavior.str.contains('noncontact')]\n",
    "elif mainDir == day14:\n",
    "    socialCvBoris = socialCvBoris[socialCvBoris.Subject.str.contains(novel)]\n",
    "socialCvBoris = socialCvBoris.tail(-1)\n",
    "if Boris1OrCleversys0==1:\n",
    "    socialCv = socialCvBoris\n",
    "    behaviorOfInterest = behaviorOfInterestBoris\n",
    "\n",
    "numBeforeEvent = 20\n",
    "numAfterEvent = 30\n",
    "numTotal = numBeforeEvent + numAfterEvent\n",
    "socialContactC = np.zeros([dataUsed.shape[0],numTotal,socialCv.shape[0]])\n",
    "print(socialContactC.shape)\n",
    "\n",
    "\n",
    "for ev in range(socialCv.shape[0]):\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameStart = socialCv.iloc[ev,9]\n",
    "    else: \n",
    "        scopeFrameStart = socialCv.iloc[ev,18]\n",
    "        \n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,10]\n",
    "    else:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,19]\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "    #try: #to account for events happening too close to end\n",
    "    socialContactC[:,0:numBeforeEvent-1,ev] = dataUsed.iloc[:,minianFrameStart-numBeforeEvent:minianFrameStart-1]\n",
    "    socialContactC[:,numBeforeEvent-1:numTotal,ev] = dataUsed.iloc[:,minianFrameStart:minianFrameStart+numAfterEvent+1] \n",
    "    #except:\n",
    "        #pass\n",
    "    \n",
    "    \n",
    "#socialContactC = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "#print(socialCvBoris)\n",
    "#socialCvBoris.sum(' Duration (s)')\n",
    "\n",
    "\n",
    "\n",
    "total = socialCvBoris['Duration (s)'].sum()\n",
    "print(total)\n",
    "\n",
    "#socialCvBoris\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8e11d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Assemblies_MEK\n",
    "dataUsedDf = dataUsed.to_numpy()\n",
    "np.shape(dataUsedDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edefb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(Assemblies_MEK)\n",
    "assembly_dict, fig, axs = Assemblies_MEK.find_assemblies(dataUsedDf,method='ica',nullhyp='mp',n_shuffles=1000,percentile=99,tracywidow=False,\n",
    "                              compute_activity=True, use_bool=False, plot=True)\n",
    "#assembly_dict has patterns, significance, z_data, orig_data, and activations\n",
    "\n",
    "   \n",
    "fileName = mainDirName + 'assemblies_spikes.png'\n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'assemblies/')\n",
    "\n",
    "print(len(assembly_dict['activations']))\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "#fig.savefig(saveName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68356bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96910732",
   "metadata": {},
   "outputs": [],
   "source": [
    "patterns = assembly_dict['patterns']\n",
    "activations = assembly_dict['activations']\n",
    "sorted_spiking = assembly_dict['sorted_spiking']\n",
    "sorted_colors = assembly_dict['sorted_colors']\n",
    "\n",
    "print(activations.shape)\n",
    "\n",
    "\n",
    "fig,axs = Assemblies_MEK.plot_assemblies_select(activations, sorted_spiking, colors=sorted_colors)\n",
    "\n",
    "\n",
    "fileName = mainDirName + 'assemblies_spikes_example.png'\n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'assemblies/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "\n",
    "#with open(os.path.join(saveFolder + '\\_5546_day0.pkl'), 'wb') as f:\n",
    "    #pickle.dump([assembly_dict], f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6913204",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 1) try warping novel events using nearest neighbor to equalize the num of frames for each event type\n",
    "# 2) using total novel time, subsample partner time & remove other frames\n",
    "\n",
    "import statistics \n",
    "\n",
    "totalSession = boris1['Duration (s)'].sum()\n",
    "#print(totalSession)\n",
    "\n",
    "totalPartner = socialCvBorisPartner['Duration (s)'].sum()\n",
    "totalNovel = socialCvBorisNovel['Duration (s)'].sum()\n",
    "novelTimeToAddTotal = (totalPartner-totalNovel)\n",
    "#print(middlePoint)\n",
    "\n",
    "# divide amount of necessary added time by # events to add that time to\n",
    "#novelTimeToAdd = middlePoint - totalNovel\n",
    "#partnerTimeToSubtract = totalPartner - middlePoint\n",
    "\n",
    "#print(len(socialCvBorisPartner))\n",
    "#print(len(socialCvBorisNovel))\n",
    "novelTimeToAdd = novelTimeToAddTotal / len(socialCvBorisNovel)\n",
    "#partnerTimeToSubtract = partnerTimeToSubtract / len(socialCvBorisPartner)\n",
    "#print(novelTimeToAdd)\n",
    "#print(partnerTimeToSubtract)\n",
    "\n",
    "\n",
    "# find avg conversion between behavior frame #s and minian frame #s. use that \n",
    "differenceFrameNums = socialCvBorisNovel.iloc[:,17] - socialCvBorisNovel.iloc[:,16]\n",
    "differenceScopeNums = socialCvBorisNovel.iloc[:,19] - socialCvBorisNovel.iloc[:,18]\n",
    "avgConversion = np.mean(differenceScopeNums / differenceFrameNums)\n",
    "\n",
    "\n",
    "#bug - newMinianLength changes with every event, so cant be set in stone here\n",
    "#but if I write it back into dataUsed, then the indices for that change..\n",
    "newCell = np.zeros((len(tempData),dataUsed.shape[1]+(novelTimeToAddTotal*avgConversion),socialCvBorisNovel.shape[0]))\n",
    "                   \n",
    "#print(socialCvBorisNovel.shape[0])\n",
    "#print(newMinianLength)\n",
    "\n",
    "for ev in [0]:#range(socialCvBorisNovel.shape[0]):\n",
    "\n",
    "    # pull out cam and scope frame indices\n",
    "    camFrameStart = socialCvBorisNovel.iloc[ev,16]\n",
    "    camFrameStop = socialCvBorisNovel.iloc[ev,17]\n",
    "    scopeFrameStart = socialCvBorisNovel.iloc[ev,18]\n",
    "    scopeFrameEnd = socialCvBorisNovel.iloc[ev,19]\n",
    "\n",
    "    #display(socialCvBorisNovel.iloc[0:5,:])\n",
    "\n",
    "    #convert seconds into frames to add\n",
    "    framesToAdd = novelTimeToAdd * 50\n",
    "    # add new behavior frames. these will become 1s downstream\n",
    "    newEnd = (round(camFrameStop+framesToAdd))\n",
    "    socialCvBorisNovel.iloc[ev,17] = newEnd\n",
    "        # adjust the rest of the frames to account for this change\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,16] = socialCvBorisNovel.iloc[ev+1:-1,16] + int(framesToAdd)\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,17] = socialCvBorisNovel.iloc[ev+1:-1,17] + int(framesToAdd)\n",
    "\n",
    "    # now go into neural data and interpolate to warp equivalent amount of neural data\n",
    "\n",
    "    # find new minianFrameStart and minianFrameEnd\n",
    "    # go into dataUsed and interpolate it, making dataUsed larger\n",
    "    scopeFramesToAdd = int(framesToAdd * avgConversion)\n",
    "    newScopeFrameEnd = scopeFrameEnd + scopeFramesToAdd\n",
    "    socialCvBorisNovel.iloc[ev,19] = newScopeFrameEnd\n",
    "\n",
    "    # adjust the rest of the frames to account for this change\n",
    "    # when indexed in the future, it will ultimately point to a modified dataUsed that has new frames\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,18] = socialCvBorisNovel.iloc[ev+1:-1,18] + int(scopeFramesToAdd)\n",
    "    socialCvBorisNovel.iloc[ev+1:-1,19] = socialCvBorisNovel.iloc[ev+1:-1,19] + int(scopeFramesToAdd)\n",
    "\n",
    "    # get the typical minian frame indices\n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "\n",
    "\n",
    "    # get new minian frame end index, and new length of data\n",
    "    newMinianFrameEnd = round(newScopeFrameEnd / dsFactorUsed)\n",
    "    newMinianLength = newMinianFrameEnd - minianFrameStart\n",
    "    existingMinianLength = minianFrameEnd - minianFrameStart\n",
    "\n",
    "\n",
    "    print(newMinianLength)\n",
    "    print(existingMinianLength)\n",
    "\n",
    "    # pull out the existing data\n",
    "    tempData = dataUsed.iloc[:,minianFrameStart:minianFrameEnd]\n",
    "\n",
    "\n",
    "    #Initialize new numpy matrix for cells with new length of data\n",
    "    newCell = np.zeros((len(tempData),newMinianLength))\n",
    "\n",
    "    # loop through cells\n",
    "    for cell in [0]:#[0]:#range(len(dataUsed)):\n",
    "        #print(cell)\n",
    "        tempDataCell = tempData.iloc[cell,:] \n",
    "\n",
    "\n",
    "        # to determine how many times to repeat Minian values \n",
    "        multiplyFactor = (round(newMinianLength/existingMinianLength))\n",
    "        #print(multiplyFactor)\n",
    "\n",
    "    \n",
    "        tempDataCell = tempDataCell.to_numpy()\n",
    "        tempDataCell = np.repeat(tempDataCell,multiplyFactor+1,axis=0)\n",
    "\n",
    "        #print(newMinianLength)\n",
    "\n",
    "        #now, take out the # of frames that we overshot by\n",
    "        #shitty way to do it\n",
    "        change = (len(tempDataCell) - newMinianLength)\n",
    "        randDelete = random.sample(range(0,len(tempDataCell)),change)\n",
    "        tempDataCell = np.delete(tempDataCell,randDelete)\n",
    "        #print(len(tempDataCell))\n",
    "\n",
    "        # insert into array\n",
    "        newCell[cell,:] = tempDataCell\n",
    "\n",
    "        #tempDataCell  = pd.DataFrame(tempDataCell)\n",
    "        #tempData.iloc[cell,:] = tempDataCell\n",
    "        #dataWriteIn = newCell[cell,0:existingMinianLength]\n",
    "        \n",
    "        \n",
    "        #len(dataWriteIn.columns)\n",
    "        \n",
    "        #dataWriteIn = newCell.reshape((existingMinianLength,))\n",
    "        #dataWriteIn = pd.DataFrame(newCell[cell,0:existingMinianLength])\n",
    "        #dataWriteIn = pd.DataFrame(dataWriteIn)\n",
    "        #dataWriteIn = dataWriteIn.reshape((existingMinianLength,))\n",
    "    dataWriteIn = newCell[:,0:existingMinianLength]\n",
    "    print(dataWriteIn.shape)\n",
    "    dataUsed.iloc[:,minianFrameStart:minianFrameEnd] = dataWriteIn\n",
    "    \n",
    "    print(dataUsed.shape)\n",
    "        \n",
    "    # now for anything beyond existing MinianLength, need to expand the # of columns\n",
    "    numRemaining = newMinianLength - existingMinianLength\n",
    "    remainingData = newCell[:,-numRemaining:]\n",
    "    numSamples = (remainingData.shape[0])\n",
    "    #print(minianFrameEnd+1)\n",
    "    #print(minianFrameEnd+1+numSamples)\n",
    "    #print([minianFrameEnd+1:minianFrameEnd+1+numSamples])\n",
    "    #dataUsed.insert(minianFrameEnd+1:minianFrameEnd+1+remainingData.shape,[],remainingData)\n",
    "    #dataUsed.insert[cell,minianFrameEnd+1,'columns'] = remainingData    \n",
    "    #display(pd.DataFrame(remainingData))\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(remainingData.shape)\n",
    "    print(dataUsed.shape)\n",
    "    \n",
    "    \n",
    "    remainingData = pd.DataFrame(remainingData)\n",
    "    unitIdNames = (dataUsed.index)\n",
    "    remainingData.index = unitIdNames\n",
    "    \n",
    "    dataUsed = dataUsed.join(remainingData,rsuffix='_')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126f7318",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(dataUsed)\n",
    "print(remainingData.shape)\n",
    "print(dataWriteIn.shape)\n",
    "print(unitIdNames)\n",
    "\n",
    "#dataUsed2 = dataUsed.join(remainingData,rsuffix='_')\n",
    "#print(dataUsed2.shape)\n",
    "display(dataUsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18e489a",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "## BEHAVIOR SPECIFIC PCA\n",
    "socialContactC_acrossCells = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "socialContactC_acrossCells = socialContactC_acrossCells.transpose()\n",
    "model = pca(n_components=0.95)\n",
    "results = model.fit_transform(socialContactC_acrossCells)\n",
    "fig,ax = model.plot()\n",
    "\n",
    "fileName = mainDirName + 'BehaviorPCA.png'\n",
    "if mainDir == day2:\n",
    "    fileName = mainDirName + 'NovelBehaviorPCA.png'\n",
    "elif mainDir == day14:\n",
    "    fileName = mainDirName + 'PartnerBehaviorPCA.png'\n",
    "    \n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'PCA/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "fig.savefig(saveName)\n",
    "\n",
    "#fig.savefig(directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442100dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for running AUC shuffles\n",
    "def auROCshuffle(cellActivity):\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "\n",
    "    # initialize TPR and FPR for each of the 100 steps\n",
    "    TPR_cell = [0] * 100\n",
    "    FPR_cell = [0] * 100\n",
    "\n",
    "    #max(cellActivityZScore)\n",
    "    #min(cellActivityZScore)\n",
    "\n",
    "    # define 100 steps of z-scored DF/F\n",
    "    steps = np.linspace(min(cellActivityZScore),max(cellActivityZScore),num=100)\n",
    "\n",
    "    for st in range(len(steps)):\n",
    "        # iter through steps, calculate metrics, aggregate\n",
    "        indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "        indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for ind in range(len(indices)):\n",
    "            behaviorPresence  = contactBinary[indices[ind]]\n",
    "            if behaviorPresence==1:\n",
    "                TP = TP + 1\n",
    "            if behaviorPresence==0:\n",
    "                FP = FP + 1\n",
    "    \n",
    "        for indBelow in range(len(indicesBelow)):\n",
    "            behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "            if behaviorPresence==1:\n",
    "                FN = FN + 1\n",
    "            if behaviorPresence==0:\n",
    "                TN = TN + 1\n",
    "        #try:\n",
    "        TPR_cell[st] = TP / (TP + FN)\n",
    "        #except:\n",
    "            #sometimes TPR is dividing by 0 b/c at a given threshold, there were no true positives and no false negatives yet\n",
    "            #TPR_cell[st] = 0\n",
    "            #print(st)\n",
    "            #print(ind)\n",
    "        if doPRC==0:\n",
    "            FPR_cell[st] = FP / (FP + TN)\n",
    "        elif doPRC==1:\n",
    "            FPR_cell[st] = TP / (TP + FP) #actually precision\n",
    "\n",
    "    # plot AUCs on top of one another and write out AUC\n",
    "    #plt.plot(FPR_cell,TPR_cell,'b')\n",
    "    if doPRC==1:\n",
    "        AUC_shuffles = auc(TPR_cell,FPR_cell)\n",
    "    elif doPRC==0:\n",
    "        AUC_shuffles = auc(FPR_cell,TPR_cell)\n",
    "    \n",
    "    return AUC_shuffles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9b6832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cellsKept.shape)\n",
    "print(activations.shape)\n",
    "cellsKept = pd.DataFrame(activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f4469",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "runShuffle = 1\n",
    "doPRC = 1\n",
    "import nn_interpolate\n",
    "\n",
    "#construct binary vector of behavior yes/no\n",
    "contactBinary = [0] * numMinianDownsample\n",
    "\n",
    "from collections import deque\n",
    "from random import randint\n",
    "\n",
    "# go through behaviors, find the minian frames they align to, and assign those as 1s\n",
    "for ev in range(socialCv.shape[0]):\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameStart = socialCv.iloc[ev,9] #this is \n",
    "    else: \n",
    "        scopeFrameStart = socialCv.iloc[ev,18]\n",
    "        \n",
    "    minianFrameStart = scopeFrameStart/dsFactorUsed\n",
    "    minianFrameStart = round(minianFrameStart)\n",
    "    if Boris1OrCleversys0 == 0:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,10]\n",
    "    else:\n",
    "        scopeFrameEnd = socialCv.iloc[ev,19]\n",
    "    minianFrameEnd = scopeFrameEnd/dsFactorUsed\n",
    "    minianFrameEnd = round(minianFrameEnd)\n",
    "    temp = np.tile(1,minianFrameEnd-minianFrameStart) #vector of 1s\n",
    "    temp = np.ndarray.tolist(temp)\n",
    "    contactBinary[minianFrameStart:minianFrameEnd] = temp #insert 1s into the binary vector\n",
    "\n",
    "\n",
    "#count_1 = contactBinary.count(1)\n",
    "if doPRC==0:\n",
    "    fileName = mainDirName + 'auROC.png'\n",
    "elif doPRC==1:\n",
    "    fileName = mainDirName + 'PRC.png'\n",
    "\n",
    "\n",
    "if mainDir == day2:\n",
    "    if runPartner1OrNovel0==0:\n",
    "        fileName = mainDirName + 'novel_PRC.png'\n",
    "    elif runPartner1OrNovel0==1:\n",
    "        fileName = mainDirName + 'partner_PRC.png' \n",
    "elif mainDir == day14:\n",
    "    fileName = mainDirName + 'novel_PRC.png'\n",
    "    \n",
    "\n",
    "saveFolder = os.path.join(writeOutDir,'auROC/')\n",
    "\n",
    "isExist = os.path.exists(saveFolder)\n",
    "if not isExist:\n",
    "    os.makedirs(saveFolder)\n",
    "    \n",
    "saveName = saveFolder + fileName\n",
    "\n",
    "\n",
    "\n",
    "# initialize AUC vector\n",
    "AUC_cells = [0] * cellsKept.shape[0]\n",
    "\n",
    "fig = plt.figure()\n",
    "\n",
    "#if warp==1, I can change cellsKept into a numpy array that includes mods \n",
    "\n",
    "# iterate through cells\n",
    "for cell in range(cellsKept.shape[0]):\n",
    "    print(cell)\n",
    "    cellNum = cell\n",
    "    cellActivity = cellsKept.iloc[cellNum,:]\n",
    "    cellActivity = cellActivity.tolist()\n",
    "    #print(cellActivity)\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "\n",
    "    # initialize TPR and FPR for each of the 100 steps\n",
    "    TPR_cell = [0] * 100\n",
    "    FPR_cell = [0] * 100\n",
    "\n",
    "    #max(cellActivityZScore)\n",
    "    #min(cellActivityZScore)\n",
    "\n",
    "    # define 100 steps of z-scored DF/F\n",
    "    steps = np.linspace(min(cellActivityZScore),max(cellActivityZScore),num=100)\n",
    "\n",
    "    for st in range(len(steps)):\n",
    "        # iter through steps, calculate metrics, aggregate\n",
    "        indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "        indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "        TP = 0\n",
    "        FP = 0\n",
    "        TN = 0\n",
    "        FN = 0\n",
    "        for ind in range(len(indices)):\n",
    "            behaviorPresence  = contactBinary[indices[ind]]\n",
    "            if behaviorPresence==1:\n",
    "                TP = TP + 1\n",
    "            if behaviorPresence==0:\n",
    "                FP = FP + 1\n",
    "    \n",
    "        for indBelow in range(len(indicesBelow)):\n",
    "            behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "            if behaviorPresence==1:\n",
    "                FN = FN + 1\n",
    "            if behaviorPresence==0:\n",
    "                TN = TN + 1\n",
    "                \n",
    "                \n",
    "        if doPRC==0:\n",
    "            FPR_cell[st] = FP / (FP + TN)\n",
    "        elif doPRC==1:\n",
    "            FPR_cell[st] = TP / (TP + FP) #actually precision\n",
    "        \n",
    "        #try:\n",
    "        TPR_cell[st] = TP / (TP + FN)\n",
    "        #except:\n",
    "            #need to figure out why a few cells are trying to divide by zero \n",
    "            #TPR_cell[st] = 0\n",
    "            #import pdb; pdb.set_trace()\n",
    "            #print(st)\n",
    "            #print(ind)\n",
    "        #print(TPR_cell[st])\n",
    "        #print(FPR_cell[st])   \n",
    " \n",
    "\n",
    "    # plot AUCs on top of one another and write out AUC\n",
    "    if doPRC==1:\n",
    "        AUC_cells[cell] = auc(TPR_cell,FPR_cell)\n",
    "    elif doPRC==0:\n",
    "        AUC_cells[cell] = auc(FPR_cell,TPR_cell)\n",
    "        \n",
    "        \n",
    "    #AUC_cells[cell] = auc(FPR_cell,TPR_cell)\n",
    "    \n",
    "    if runShuffle==1:    \n",
    "    \n",
    "        AUC_shuffleAll = [0] * 100\n",
    "        items = deque(cellActivity)\n",
    "        for shuffle in range((100)):\n",
    "            #print(shuffle)\n",
    "            items.rotate(randint(0,len(cellActivityZScore)))\n",
    "            shuffledCellActivity = list(items)\n",
    "            AUC_shuffleAll[shuffle] = auROCshuffle(shuffledCellActivity)\n",
    "            #print(AUC_shuffleAll[shuffle])\n",
    "        shufflesNoZeros = [i for i in AUC_shuffleAll if i!= 0]\n",
    "        if doPRC==0:\n",
    "            if AUC_cells[cell] > np.percentile(shufflesNoZeros,97.5):\n",
    "                plt.plot(FPR_cell,TPR_cell,'r')\n",
    "            elif AUC_cells[cell] < np.percentile(shufflesNoZeros,2.5):\n",
    "                plt.plot(FPR_cell,TPR_cell,'r')\n",
    "            else:\n",
    "                plt.plot(FPR_cell,TPR_cell,'b')\n",
    "        elif doPRC==1:\n",
    "            if AUC_cells[cell] > np.percentile(shufflesNoZeros,97.5):\n",
    "                plt.plot(TPR_cell,FPR_cell,'r')\n",
    "            elif AUC_cells[cell] < np.percentile(shufflesNoZeros,2.5):\n",
    "                plt.plot(TPR_cell,FPR_cell,'r')\n",
    "            else:\n",
    "                plt.plot(TPR_cell,FPR_cell,'b')            \n",
    "            \n",
    "    elif runShuffle==0:\n",
    "        \n",
    "        if doPRC==0:\n",
    "            plt.plot(FPR_cell,TPR_cell,'b')\n",
    "        elif doPRC==1:\n",
    "            plt.plot(TPR_cell,FPR_cell,'b')\n",
    "        \n",
    "        \n",
    "if doPRC==1:\n",
    "    plt.xlabel(\"Recall\")\n",
    "    plt.ylabel(\"Precision\")\n",
    "elif doPRC==0:\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "fig.savefig(saveName)\n",
    "#need a shuffle procedure\n",
    "    \n",
    "#with open(writeOutDir, 'wb') as f:\n",
    "    #pickle.dump([AUC_cells], f)\n",
    "\n",
    "\n",
    "    \n",
    "#temp = np.tile(1,minianFrameEnd-minianFrameStart)\n",
    "#temp = np.ndarray.tolist(temp)\n",
    "#temp\n",
    "#ls = [type(item) for item in temp]\n",
    "#print(ls)\n",
    "#np.tile(1,minianFrameEnd-minianFrameStart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db038e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shufflesNoZeros\n",
    "AUC_cells[cell]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abf1533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d28f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "st=0\n",
    "# iter through steps, calculate metrics, aggregate\n",
    "indices = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] >= steps[st]]\n",
    "indicesBelow = [i for i in range(len(cellActivityZScore)) if cellActivityZScore[i] < steps[st]]\n",
    "\n",
    "\n",
    "TP = 0\n",
    "FP = 0\n",
    "TN = 0\n",
    "FN = 0\n",
    "        \n",
    "for ind in range(len(indices)):\n",
    "    behaviorPresence  = contactBinary[indices[ind]]\n",
    "    if behaviorPresence==1:\n",
    "        TP = TP + 1\n",
    "    if behaviorPresence==0:\n",
    "        FP = FP + 1\n",
    "    \n",
    "for indBelow in range(len(indicesBelow)):\n",
    "    behaviorPresence = contactBinary[indicesBelow[indBelow]]\n",
    "    if behaviorPresence==1:\n",
    "        FN = FN + 1\n",
    "    if behaviorPresence==0:\n",
    "        TN = TN + 1\n",
    "                \n",
    "                \n",
    "print(len(indices))\n",
    "print(TP)\n",
    "print(FN)\n",
    "\n",
    "print(len(indicesBelow))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d2f41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "from random import randint\n",
    "\n",
    "items=deque(cellActivity)\n",
    "items.rotate(randint(0,len(cellActivity)))\n",
    "shuffledCellActivity = list(items)\n",
    "\n",
    "#print(cellActivity[0:5])\n",
    "\n",
    "#items = deque(cellActivity)\n",
    "#shuffleBy = randint(0,len(cellActivity))\n",
    "#print(shuffleBy)\n",
    "    \n",
    "#items.rotate(shuffleBy)\n",
    "\n",
    "#new = list(items)\n",
    "#print(new[0:5])\n",
    "\n",
    "\n",
    "#items.\n",
    "\n",
    "#cellActivity.append(cellActivity.pop(0))\n",
    "\n",
    "#print(cellActivity[0:5])\n",
    "\n",
    "#print(cellActivityShuffled[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ebea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_shuffleAll = [0] * 100\n",
    "items = deque(cellActivity)\n",
    "for shuffle in range((100)):\n",
    "    items.rotate(randint(0,len(cellActivity)))\n",
    "    shuffledCellActivity = list(items)\n",
    "    AUC_shuffleAll[shuffle] = auROCshuffle(shuffledCellActivity)\n",
    "print(AUC_shuffleAll)\n",
    "if AUC_cells[cell] > np.percentile(AUC_shuffleAll,97.5):\n",
    "    #color it red\n",
    "    elif AUC_cells[cell] < np.percentile(AUC_shuffleAll,2.5):\n",
    "        # color it red\n",
    "    else:\n",
    "        # color it blue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c74dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_cells[cell] > np.percentile(AUC_shuffleAll,95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bce9b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688af3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print('computed AUC: {}'.format(auc(FPR_cell,TPR_cell)))\n",
    "\n",
    "with open(os.path.join(writeOutDir + '\\AUC_N.pkl'), 'wb') as f:\n",
    "    pickle.dump([AUC_cells], f)\n",
    "    \n",
    "indexMaxAUC = [i for i in range(len(AUC_cells)) if AUC_cells[i] == max(AUC_cells)]\n",
    "indexMaxAUC\n",
    "\n",
    "ev\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d86ff77",
   "metadata": {},
   "outputs": [],
   "source": [
    "openDir0 = os.path.join(mainDir0 + '/analysesOutput/AUC.pkl')\n",
    "openDir1 = os.path.join(mainDir1 + '/analysesOutput/AUC.pkl')\n",
    "openDir2 = os.path.join(mainDir2 + '/analysesOutput/AUC.pkl')\n",
    "\n",
    "with open(openDir0, 'rb') as f:\n",
    "    AUC_0 = pickle.load(f)\n",
    "with open(openDir1, 'rb') as f:\n",
    "    AUC_1 = pickle.load(f)    \n",
    "with open(openDir2, 'rb') as f:\n",
    "    AUC_2 = pickle.load(f)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e73e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUC_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18e880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_ind(AUC_0,AUC_1,axis=1)\n",
    "\n",
    "#scipy.mean(AUC_0) - scipy.mean(AUC_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492d445b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "\n",
    "\n",
    "# initialize AUC vector\n",
    "AUC_cells = [0] * cellsKept.shape[0]\n",
    "\n",
    "# iterate through cells\n",
    "for cell in range(cellsKept.shape[0]):\n",
    "    cellNum = cell\n",
    "    cellActivity = cellsKept.iloc[cellNum,:]\n",
    "    cellActivity = cellActivity.tolist()\n",
    "    cellActivityZScore = stats.zscore(cellActivity)\n",
    "    \n",
    "    fpr, tpr, thresholds = roc_curve(contactBinary, cellActivityZScore)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cb365",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting by cell\n",
    "\n",
    "figTotal,axTotal = plt.subplots(15,3,figsize=(10,10))\n",
    "for cell in range(socialContactC.shape[0]):\n",
    "    cellActivity = socialContactC[cell,:,:]\n",
    "    socialContactMeans = np.nanmean(cellActivity,axis=1)\n",
    "    socialContactSte = np.nanstd(cellActivity,axis=1)\n",
    "    socialContactSte = socialContactSte / np.sqrt(cellActivity.shape[1])\n",
    "\n",
    "    xval = np.arange(numTotal)\n",
    "    plt.subplot(15,3,cell+1)\n",
    "    plt.errorbar(xval,socialContactMeans,socialContactSte,linestyle='None')\n",
    "    #plt.xlabel('Time relative to social contact (sec)')\n",
    "    #plt.ylabel('DF/F')\n",
    "    plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])\n",
    "    #ax.set_ylim(-0.05, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634b438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plotting across cells\n",
    "socialContactC_acrossCells = np.nanmean(socialContactC,axis=2) #nanmean across bouts\n",
    "\n",
    "socialContactMeans = np.nanmedian(socialContactC_acrossCells,axis=0) #across cells\n",
    "socialContactSte = np.nanstd(socialContactC_acrossCells,axis=0)\n",
    "socialContactSte = socialContactSte / np.sqrt(socialContactC_acrossCells.shape[0])\n",
    "\n",
    "\n",
    "xval = np.arange(numTotal)\n",
    "plt.subplot()\n",
    "plt.errorbar(xval,socialContactMeans,socialContactSte,linestyle='None')\n",
    "plt.xlabel('Time relative to social contact (sec)')\n",
    "plt.ylabel('DF/F')\n",
    "plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e02839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cellNum = 35\n",
    "cellActivity = socialContactC[cellNum,:,:]\n",
    "# plot all 83 traces on one plot\n",
    "\n",
    "xval = np.arange(numTotal)\n",
    "\n",
    "np.shape(cellActivity)\n",
    "for bout in range(cellActivity.shape[1]):\n",
    "    plt.plot(xval,cellActivity[:,bout])\n",
    "    \n",
    "    plt.xticks(np.arange(0,60,step=20),['-1.5', '0', '1.5', '3'])\n",
    "    plt.xlabel('Time relative to social approach (sec)')\n",
    "    plt.ylabel('DF/F')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
